{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeee3b78",
   "metadata": {},
   "source": [
    "# Fed-Audit-GAN V9: Kaggle Edition (2x T4 GPU)\n",
    "\n",
    "## Optimized for Kaggle with Multi-GPU Support\n",
    "\n",
    "### Key Features:\n",
    "- Multi-GPU training with DataParallel\n",
    "- Direct Kaggle dataset integration\n",
    "- WandB logging\n",
    "- Proper (X, Y, A) fairness framework\n",
    "- Counterfactual GAN auditing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdd4c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Kaggle Setup and GPU Check\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Check if running on Kaggle\n",
    "IS_KAGGLE = os.path.exists('/kaggle/input')\n",
    "print(f\"Running on Kaggle: {IS_KAGGLE}\")\n",
    "\n",
    "# Install required packages\n",
    "!pip install wandb -q\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# GPU Setup\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        print(f\"    Memory: {torch.cuda.get_device_properties(i).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "# Set device - use all available GPUs\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "NUM_GPUS = torch.cuda.device_count()\n",
    "print(f\"\\nUsing device: {device} with {NUM_GPUS} GPU(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f743476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Import All Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torch.nn.parallel import DataParallel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from copy import deepcopy\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    # Optimize for T4 GPUs\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47687bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Initialize WandB\n",
    "import wandb\n",
    "\n",
    "# For Kaggle, use anonymous mode or set your API key\n",
    "# Option 1: Anonymous mode\n",
    "# wandb.login(anonymous='allow')\n",
    "\n",
    "# Option 2: Use Kaggle secrets (recommended)\n",
    "# Add your WandB API key to Kaggle secrets with key name 'WANDB_API_KEY'\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "try:\n",
    "    user_secrets = UserSecretsClient()\n",
    "    wandb_key = user_secrets.get_secret(\"WANDB_API_KEY\")\n",
    "    wandb.login(key=wandb_key)\n",
    "    print(\"Logged in to WandB with API key!\")\n",
    "except:\n",
    "    print(\"WandB API key not found in secrets. Using anonymous mode.\")\n",
    "    wandb.login(anonymous='allow')\n",
    "\n",
    "# Configuration optimized for 2x T4 GPUs\n",
    "CONFIG = {\n",
    "    # Data settings\n",
    "    'dataset': 'adult_income',\n",
    "    'sensitive_attribute': 'sex',\n",
    "    'test_size': 0.2,\n",
    "    \n",
    "    # FL settings - optimized for 2x T4\n",
    "    'num_clients': 10,\n",
    "    'num_rounds': 50,\n",
    "    'local_epochs': 3,\n",
    "    'batch_size': 256,  # Larger batch for multi-GPU\n",
    "    'learning_rate': 0.001,\n",
    "    'client_fraction': 0.5,\n",
    "    \n",
    "    # Model settings\n",
    "    'hidden_dims': [256, 128, 64],  # Slightly larger model\n",
    "    \n",
    "    # GAN Auditor settings\n",
    "    'generator_hidden_dims': [128, 64],\n",
    "    'discriminator_hidden_dims': [128, 64],\n",
    "    'auditor_epochs': 10,\n",
    "    'auditor_lr': 0.0002,\n",
    "    'lambda_realism': 1.0,\n",
    "    'lambda_bias': 0.5,\n",
    "    'lambda_similarity': 0.3,\n",
    "    \n",
    "    # Fairness settings\n",
    "    'fairness_weight': 0.3,\n",
    "    \n",
    "    # Hardware\n",
    "    'num_gpus': NUM_GPUS,\n",
    "    'seed': SEED,\n",
    "}\n",
    "\n",
    "# Initialize wandb run\n",
    "run = wandb.init(\n",
    "    project=\"Fed-Audit-GAN-V9\",\n",
    "    name=f\"kaggle_2xT4_{CONFIG['num_rounds']}rounds\",\n",
    "    config=CONFIG,\n",
    "    tags=[\"v9\", \"kaggle\", \"multi-gpu\", \"adult-income\"],\n",
    ")\n",
    "\n",
    "print(f\"\\nWandB initialized!\")\n",
    "print(f\"Run URL: {wandb.run.url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b684b48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Load Adult Income Dataset from Kaggle\n",
    "\n",
    "class AdultIncomeDataset(Dataset):\n",
    "    \"\"\"Adult Income Dataset with proper (X, Y, A) separation.\"\"\"\n",
    "    \n",
    "    def __init__(self, features: np.ndarray, labels: np.ndarray, \n",
    "                 sensitive_attrs: np.ndarray, feature_names: List[str]):\n",
    "        self.features = torch.FloatTensor(features)\n",
    "        self.labels = torch.LongTensor(labels)\n",
    "        self.sensitive_attrs = torch.LongTensor(sensitive_attrs)\n",
    "        self.feature_names = feature_names\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'features': self.features[idx],\n",
    "            'label': self.labels[idx],\n",
    "            'sensitive': self.sensitive_attrs[idx]\n",
    "        }\n",
    "\n",
    "\n",
    "def load_adult_income_kaggle(sensitive_attr: str = 'sex'):\n",
    "    \"\"\"\n",
    "    Load Adult Income dataset from Kaggle.\n",
    "    Dataset: https://www.kaggle.com/datasets/wenruliu/adult-income-dataset\n",
    "    \"\"\"\n",
    "    # Kaggle dataset path\n",
    "    if IS_KAGGLE:\n",
    "        DATA_PATH = '/kaggle/input/adult-income-dataset/adult.csv'\n",
    "    else:\n",
    "        DATA_PATH = './data/adult.csv'\n",
    "    \n",
    "    print(f\"Loading dataset from: {DATA_PATH}\")\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    \n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(f\"Columns: {df.columns.tolist()}\")\n",
    "    \n",
    "    # Clean column names\n",
    "    df.columns = df.columns.str.strip().str.replace(' ', '_').str.lower()\n",
    "    \n",
    "    # Handle missing values\n",
    "    df = df.replace('?', np.nan).replace(' ?', np.nan)\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # Find target column\n",
    "    target_col = None\n",
    "    for col in df.columns:\n",
    "        if 'income' in col.lower():\n",
    "            target_col = col\n",
    "            break\n",
    "    if target_col is None:\n",
    "        target_col = df.columns[-1]\n",
    "    \n",
    "    print(f\"\\nTarget column: {target_col}\")\n",
    "    print(f\"Target values: {df[target_col].unique()}\")\n",
    "    \n",
    "    # Encode target (Y)\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['label'] = label_encoder.fit_transform(df[target_col].astype(str).str.strip())\n",
    "    print(f\"Label encoding: {dict(zip(label_encoder.classes_, range(len(label_encoder.classes_))))}\")\n",
    "    \n",
    "    # Find sensitive attribute column\n",
    "    sensitive_col = None\n",
    "    for col in df.columns:\n",
    "        if sensitive_attr.lower() in col.lower():\n",
    "            sensitive_col = col\n",
    "            break\n",
    "    \n",
    "    if sensitive_col is None:\n",
    "        raise ValueError(f\"Sensitive attribute '{sensitive_attr}' not found\")\n",
    "    \n",
    "    print(f\"\\nSensitive attribute: {sensitive_col}\")\n",
    "    print(f\"Values: {df[sensitive_col].value_counts().to_dict()}\")\n",
    "    \n",
    "    # Encode sensitive attribute (A)\n",
    "    sensitive_encoder = LabelEncoder()\n",
    "    df['sensitive'] = sensitive_encoder.fit_transform(df[sensitive_col].astype(str).str.strip())\n",
    "    print(f\"Sensitive encoding: {dict(zip(sensitive_encoder.classes_, range(len(sensitive_encoder.classes_))))}\")\n",
    "    \n",
    "    # Feature columns (X)\n",
    "    exclude_cols = [target_col, sensitive_col, 'label', 'sensitive']\n",
    "    feature_cols = [col for col in df.columns if col not in exclude_cols]\n",
    "    \n",
    "    # Separate categorical and numerical\n",
    "    categorical_cols = df[feature_cols].select_dtypes(include=['object']).columns.tolist()\n",
    "    numerical_cols = df[feature_cols].select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    \n",
    "    print(f\"\\nCategorical features: {len(categorical_cols)}\")\n",
    "    print(f\"Numerical features: {len(numerical_cols)}\")\n",
    "    \n",
    "    # One-hot encode categorical\n",
    "    df_encoded = pd.get_dummies(df[feature_cols], columns=categorical_cols, drop_first=True)\n",
    "    \n",
    "    # Normalize numerical\n",
    "    scaler = StandardScaler()\n",
    "    for col in numerical_cols:\n",
    "        if col in df_encoded.columns:\n",
    "            df_encoded[col] = scaler.fit_transform(df_encoded[[col]])\n",
    "    \n",
    "    # Extract arrays\n",
    "    features = df_encoded.values.astype(np.float32)\n",
    "    labels = df['label'].values\n",
    "    sensitive_attrs = df['sensitive'].values\n",
    "    feature_names = df_encoded.columns.tolist()\n",
    "    \n",
    "    print(f\"\\nFinal feature dimension: {features.shape[1]}\")\n",
    "    print(f\"Total samples: {len(labels)}\")\n",
    "    print(f\"Positive rate: {labels.mean():.2%}\")\n",
    "    print(f\"Sensitive attr rate (group 1): {sensitive_attrs.mean():.2%}\")\n",
    "    \n",
    "    return features, labels, sensitive_attrs, feature_names\n",
    "\n",
    "\n",
    "# Load data\n",
    "features, labels, sensitive_attrs, feature_names = load_adult_income_kaggle(\n",
    "    sensitive_attr=CONFIG['sensitive_attribute']\n",
    ")\n",
    "\n",
    "INPUT_DIM = features.shape[1]\n",
    "print(f\"\\n✅ Data loaded! Input dimension: {INPUT_DIM}\")\n",
    "\n",
    "wandb.log({\n",
    "    'data/num_samples': len(labels),\n",
    "    'data/num_features': INPUT_DIM,\n",
    "    'data/positive_rate': labels.mean(),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842c80c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Create Heterogeneous Client Partitions\n",
    "\n",
    "def create_heterogeneous_clients(\n",
    "    features: np.ndarray,\n",
    "    labels: np.ndarray, \n",
    "    sensitive_attrs: np.ndarray,\n",
    "    num_clients: int,\n",
    "    bias_strength: float = 0.7\n",
    ") -> Dict[int, Dict]:\n",
    "    \"\"\"\n",
    "    Create heterogeneous client partitions:\n",
    "    - 40% biased toward majority group (biased)\n",
    "    - 40% biased toward minority group (fairness-critical)\n",
    "    - 20% balanced\n",
    "    \"\"\"\n",
    "    n_samples = len(labels)\n",
    "    indices = np.arange(n_samples)\n",
    "    \n",
    "    # Separate by sensitive attribute\n",
    "    group_0_idx = indices[sensitive_attrs == 0]\n",
    "    group_1_idx = indices[sensitive_attrs == 1]\n",
    "    \n",
    "    np.random.shuffle(group_0_idx)\n",
    "    np.random.shuffle(group_1_idx)\n",
    "    \n",
    "    # Client type distribution\n",
    "    n_biased_0 = int(num_clients * 0.4)\n",
    "    n_biased_1 = int(num_clients * 0.4)\n",
    "    \n",
    "    client_data = {}\n",
    "    samples_per_client = n_samples // num_clients\n",
    "    g0_ptr, g1_ptr = 0, 0\n",
    "    \n",
    "    for cid in range(num_clients):\n",
    "        if cid < n_biased_0:\n",
    "            # Biased toward group 0 (majority)\n",
    "            n_from_g0 = int(samples_per_client * bias_strength)\n",
    "            n_from_g1 = samples_per_client - n_from_g0\n",
    "            client_type = 'biased_majority'\n",
    "        elif cid < n_biased_0 + n_biased_1:\n",
    "            # Biased toward group 1 (fairness-critical)\n",
    "            n_from_g1 = int(samples_per_client * bias_strength)\n",
    "            n_from_g0 = samples_per_client - n_from_g1\n",
    "            client_type = 'fairness_critical'\n",
    "        else:\n",
    "            # Balanced\n",
    "            n_from_g0 = samples_per_client // 2\n",
    "            n_from_g1 = samples_per_client - n_from_g0\n",
    "            client_type = 'balanced'\n",
    "        \n",
    "        # Get indices with wraparound\n",
    "        g0_end = min(g0_ptr + n_from_g0, len(group_0_idx))\n",
    "        g1_end = min(g1_ptr + n_from_g1, len(group_1_idx))\n",
    "        \n",
    "        client_indices = np.concatenate([\n",
    "            group_0_idx[g0_ptr:g0_end],\n",
    "            group_1_idx[g1_ptr:g1_end]\n",
    "        ])\n",
    "        \n",
    "        g0_ptr = g0_end % len(group_0_idx)\n",
    "        g1_ptr = g1_end % len(group_1_idx)\n",
    "        \n",
    "        np.random.shuffle(client_indices)\n",
    "        \n",
    "        client_data[cid] = {\n",
    "            'indices': client_indices,\n",
    "            'type': client_type,\n",
    "            'group_0_ratio': (sensitive_attrs[client_indices] == 0).mean(),\n",
    "            'positive_rate': labels[client_indices].mean()\n",
    "        }\n",
    "    \n",
    "    return client_data\n",
    "\n",
    "\n",
    "# Create train/test split\n",
    "X_train, X_test, y_train, y_test, a_train, a_test = train_test_split(\n",
    "    features, labels, sensitive_attrs,\n",
    "    test_size=CONFIG['test_size'],\n",
    "    random_state=SEED,\n",
    "    stratify=labels\n",
    ")\n",
    "\n",
    "print(f\"Training: {len(y_train)} | Test: {len(y_test)}\")\n",
    "\n",
    "# Create client partitions\n",
    "client_partitions = create_heterogeneous_clients(\n",
    "    X_train, y_train, a_train,\n",
    "    num_clients=CONFIG['num_clients']\n",
    ")\n",
    "\n",
    "# Display client info\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLIENT DISTRIBUTION\")\n",
    "print(\"=\"*60)\n",
    "for cid, cdata in client_partitions.items():\n",
    "    print(f\"Client {cid} ({cdata['type']:18s}): {len(cdata['indices']):5d} samples, \"\n",
    "          f\"Group0: {cdata['group_0_ratio']:.1%}, Pos: {cdata['positive_rate']:.1%}\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = AdultIncomeDataset(X_train, y_train, a_train, feature_names)\n",
    "test_dataset = AdultIncomeDataset(X_test, y_test, a_test, feature_names)\n",
    "\n",
    "print(f\"\\n✅ Datasets created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7512bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Define Models with Multi-GPU Support\n",
    "\n",
    "class GlobalClassifier(nn.Module):\n",
    "    \"\"\"Global classifier for income prediction.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim: int, hidden_dims: List[int] = [256, 128, 64]):\n",
    "        super().__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3)\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        layers.append(nn.Linear(prev_dim, 2))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "    \n",
    "    def predict_proba(self, x):\n",
    "        with torch.no_grad():\n",
    "            return F.softmax(self.forward(x), dim=1)\n",
    "\n",
    "\n",
    "class CounterfactualGenerator(nn.Module):\n",
    "    \"\"\"\n",
    "    Generates counterfactual samples x' from x where only A changes.\n",
    "    Input: (x, a_source, a_target)\n",
    "    Output: x' that looks like x but with sensitive attribute a'\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim: int, hidden_dims: List[int] = [128, 64]):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Input: features + one_hot(a) + one_hot(a')\n",
    "        total_input = input_dim + 4\n",
    "        \n",
    "        # Encoder\n",
    "        encoder_layers = []\n",
    "        prev_dim = total_input\n",
    "        for hidden_dim in hidden_dims:\n",
    "            encoder_layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.LeakyReLU(0.2),\n",
    "                nn.BatchNorm1d(hidden_dim)\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "        self.encoder = nn.Sequential(*encoder_layers)\n",
    "        \n",
    "        # Decoder\n",
    "        decoder_layers = []\n",
    "        for hidden_dim in reversed(hidden_dims[:-1]):\n",
    "            decoder_layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.LeakyReLU(0.2),\n",
    "                nn.BatchNorm1d(hidden_dim)\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "        decoder_layers.append(nn.Linear(prev_dim, input_dim))\n",
    "        decoder_layers.append(nn.Tanh())\n",
    "        self.decoder = nn.Sequential(*decoder_layers)\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.perturbation_scale = 0.5\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, a_source: torch.Tensor, a_target: torch.Tensor):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        a_source_onehot = F.one_hot(a_source, num_classes=2).float()\n",
    "        a_target_onehot = F.one_hot(a_target, num_classes=2).float()\n",
    "        \n",
    "        combined = torch.cat([x, a_source_onehot, a_target_onehot], dim=1)\n",
    "        \n",
    "        encoded = self.encoder(combined)\n",
    "        delta = self.decoder(encoded) * self.perturbation_scale\n",
    "        \n",
    "        x_cf = x + delta\n",
    "        return x_cf, delta\n",
    "\n",
    "\n",
    "class BiasDiscriminator(nn.Module):\n",
    "    \"\"\"Discriminator with dual heads: Real/Fake and Sensitive Attribute prediction.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim: int, hidden_dims: List[int] = [128, 64]):\n",
    "        super().__init__()\n",
    "        \n",
    "        shared_layers = []\n",
    "        prev_dim = input_dim\n",
    "        for hidden_dim in hidden_dims:\n",
    "            shared_layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.LeakyReLU(0.2),\n",
    "                nn.Dropout(0.3)\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        self.shared = nn.Sequential(*shared_layers)\n",
    "        self.real_fake_head = nn.Linear(prev_dim, 1)\n",
    "        self.sensitive_head = nn.Linear(prev_dim, 2)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        features = self.shared(x)\n",
    "        real_fake = torch.sigmoid(self.real_fake_head(features))\n",
    "        sensitive = self.sensitive_head(features)\n",
    "        return real_fake, sensitive\n",
    "\n",
    "\n",
    "def wrap_model_multi_gpu(model, device, num_gpus):\n",
    "    \"\"\"Wrap model with DataParallel if multiple GPUs available.\"\"\"\n",
    "    model = model.to(device)\n",
    "    if num_gpus > 1:\n",
    "        print(f\"  → Using DataParallel with {num_gpus} GPUs\")\n",
    "        model = DataParallel(model)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_model_module(model):\n",
    "    \"\"\"Get underlying module if wrapped in DataParallel.\"\"\"\n",
    "    if isinstance(model, DataParallel):\n",
    "        return model.module\n",
    "    return model\n",
    "\n",
    "\n",
    "# Initialize models\n",
    "print(\"Initializing models...\")\n",
    "\n",
    "global_model = GlobalClassifier(INPUT_DIM, CONFIG['hidden_dims'])\n",
    "global_model = wrap_model_multi_gpu(global_model, device, NUM_GPUS)\n",
    "\n",
    "generator = CounterfactualGenerator(INPUT_DIM, CONFIG['generator_hidden_dims'])\n",
    "generator = wrap_model_multi_gpu(generator, device, NUM_GPUS)\n",
    "\n",
    "discriminator = BiasDiscriminator(INPUT_DIM, CONFIG['discriminator_hidden_dims'])\n",
    "discriminator = wrap_model_multi_gpu(discriminator, device, NUM_GPUS)\n",
    "\n",
    "# Count parameters\n",
    "def count_params(m):\n",
    "    return sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nGlobal Model: {count_params(global_model):,} params\")\n",
    "print(f\"Generator: {count_params(generator):,} params\")\n",
    "print(f\"Discriminator: {count_params(discriminator):,} params\")\n",
    "\n",
    "wandb.log({\n",
    "    'model/global_params': count_params(global_model),\n",
    "    'model/generator_params': count_params(generator),\n",
    "    'model/discriminator_params': count_params(discriminator),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be10da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Fairness Auditor with Multi-GPU Support\n",
    "\n",
    "class FairnessAuditor:\n",
    "    \"\"\"GAN-based Fairness Auditor for Fed-Audit-GAN.\"\"\"\n",
    "    \n",
    "    def __init__(self, generator, discriminator, device, config, num_gpus=1):\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.device = device\n",
    "        self.config = config\n",
    "        self.num_gpus = num_gpus\n",
    "        \n",
    "        # Get underlying modules for optimizer\n",
    "        gen_module = get_model_module(generator)\n",
    "        disc_module = get_model_module(discriminator)\n",
    "        \n",
    "        self.g_optimizer = optim.Adam(gen_module.parameters(), lr=config['auditor_lr'], betas=(0.5, 0.999))\n",
    "        self.d_optimizer = optim.Adam(disc_module.parameters(), lr=config['auditor_lr'], betas=(0.5, 0.999))\n",
    "        \n",
    "        self.bias_history = []\n",
    "        \n",
    "    def train_auditor(self, global_model, dataloader, epochs=10):\n",
    "        \"\"\"Train GAN to find counterfactuals that expose bias.\"\"\"\n",
    "        global_model.eval()\n",
    "        self.generator.train()\n",
    "        self.discriminator.train()\n",
    "        \n",
    "        stats = defaultdict(list)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            epoch_g_loss, epoch_d_loss, epoch_bias = 0, 0, 0\n",
    "            n_batches = 0\n",
    "            \n",
    "            for batch in dataloader:\n",
    "                x = batch['features'].to(self.device)\n",
    "                a = batch['sensitive'].to(self.device)\n",
    "                batch_size = x.size(0)\n",
    "                a_flipped = 1 - a\n",
    "                \n",
    "                # Train Discriminator\n",
    "                self.d_optimizer.zero_grad()\n",
    "                \n",
    "                real_rf, real_sens = self.discriminator(x)\n",
    "                with torch.no_grad():\n",
    "                    x_cf, _ = self.generator(x, a, a_flipped)\n",
    "                fake_rf, _ = self.discriminator(x_cf.detach())\n",
    "                \n",
    "                real_label = torch.ones(batch_size, 1).to(self.device)\n",
    "                fake_label = torch.zeros(batch_size, 1).to(self.device)\n",
    "                \n",
    "                d_loss = (F.binary_cross_entropy(real_rf, real_label) +\n",
    "                          F.binary_cross_entropy(fake_rf, fake_label) +\n",
    "                          0.5 * F.cross_entropy(real_sens, a))\n",
    "                d_loss.backward()\n",
    "                self.d_optimizer.step()\n",
    "                \n",
    "                # Train Generator\n",
    "                self.g_optimizer.zero_grad()\n",
    "                \n",
    "                x_cf, delta = self.generator(x, a, a_flipped)\n",
    "                fake_rf, fake_sens = self.discriminator(x_cf)\n",
    "                \n",
    "                # Losses\n",
    "                g_loss_adv = F.binary_cross_entropy(fake_rf, real_label)\n",
    "                g_loss_sim = F.mse_loss(x_cf, x)\n",
    "                \n",
    "                # BIAS EXPOSURE: maximize prediction difference\n",
    "                with torch.no_grad():\n",
    "                    pred_orig = F.softmax(global_model(x), dim=1)[:, 1]\n",
    "                pred_cf = F.softmax(global_model(x_cf), dim=1)[:, 1]\n",
    "                pred_diff = torch.abs(pred_orig - pred_cf)\n",
    "                g_loss_bias = -pred_diff.mean()\n",
    "                \n",
    "                g_loss_sens = F.cross_entropy(fake_sens, a_flipped)\n",
    "                \n",
    "                g_loss = (self.config['lambda_realism'] * g_loss_adv +\n",
    "                          self.config['lambda_similarity'] * g_loss_sim +\n",
    "                          self.config['lambda_bias'] * g_loss_bias +\n",
    "                          0.3 * g_loss_sens)\n",
    "                \n",
    "                g_loss.backward()\n",
    "                self.g_optimizer.step()\n",
    "                \n",
    "                epoch_g_loss += g_loss.item()\n",
    "                epoch_d_loss += d_loss.item()\n",
    "                epoch_bias += pred_diff.mean().item()\n",
    "                n_batches += 1\n",
    "            \n",
    "            stats['g_loss'].append(epoch_g_loss / n_batches)\n",
    "            stats['d_loss'].append(epoch_d_loss / n_batches)\n",
    "            stats['bias'].append(epoch_bias / n_batches)\n",
    "        \n",
    "        return dict(stats)\n",
    "    \n",
    "    def compute_counterfactual_bias(self, global_model, dataloader):\n",
    "        \"\"\"Compute fairness metrics using counterfactual probes.\"\"\"\n",
    "        global_model.eval()\n",
    "        self.generator.eval()\n",
    "        \n",
    "        all_pred_diff = []\n",
    "        all_sensitive = []\n",
    "        boundary_crossings = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                x = batch['features'].to(self.device)\n",
    "                a = batch['sensitive'].to(self.device)\n",
    "                a_flipped = 1 - a\n",
    "                \n",
    "                x_cf, _ = self.generator(x, a, a_flipped)\n",
    "                \n",
    "                pred_orig = F.softmax(global_model(x), dim=1)\n",
    "                pred_cf = F.softmax(global_model(x_cf), dim=1)\n",
    "                \n",
    "                boundary_crossings += (pred_orig.argmax(1) != pred_cf.argmax(1)).sum().item()\n",
    "                total += x.size(0)\n",
    "                \n",
    "                all_pred_diff.append(torch.abs(pred_orig[:, 1] - pred_cf[:, 1]).cpu())\n",
    "                all_sensitive.append(a.cpu())\n",
    "        \n",
    "        all_pred_diff = torch.cat(all_pred_diff)\n",
    "        all_sensitive = torch.cat(all_sensitive)\n",
    "        \n",
    "        metrics = {\n",
    "            'cf_prediction_gap': all_pred_diff.mean().item(),\n",
    "            'cf_prediction_gap_std': all_pred_diff.std().item(),\n",
    "            'boundary_crossing_rate': boundary_crossings / total,\n",
    "            'cf_gap_group_0': all_pred_diff[all_sensitive == 0].mean().item(),\n",
    "            'cf_gap_group_1': all_pred_diff[all_sensitive == 1].mean().item(),\n",
    "        }\n",
    "        \n",
    "        # Latent Bias Discovery Rate\n",
    "        threshold = all_pred_diff.mean() + all_pred_diff.std()\n",
    "        metrics['latent_bias_discovery_rate'] = (all_pred_diff > threshold).float().mean().item()\n",
    "        \n",
    "        self.bias_history.append(metrics['cf_prediction_gap'])\n",
    "        return metrics\n",
    "    \n",
    "    def compute_client_contribution(self, global_model, client_update, dataloader, lr=1.0):\n",
    "        \"\"\"Compute client's fairness contribution: ΔB = B_before - B_after.\"\"\"\n",
    "        # Bias before\n",
    "        metrics_before = self.compute_counterfactual_bias(global_model, dataloader)\n",
    "        \n",
    "        # Apply update hypothetically\n",
    "        updated_model = deepcopy(global_model)\n",
    "        with torch.no_grad():\n",
    "            for name, param in get_model_module(updated_model).named_parameters():\n",
    "                if name in client_update:\n",
    "                    param.add_(client_update[name] * lr)\n",
    "        \n",
    "        # Bias after\n",
    "        metrics_after = self.compute_counterfactual_bias(updated_model, dataloader)\n",
    "        \n",
    "        # Contribution = reduction in bias (positive = good)\n",
    "        contribution = metrics_before['cf_prediction_gap'] - metrics_after['cf_prediction_gap']\n",
    "        \n",
    "        return contribution, metrics_before, metrics_after\n",
    "\n",
    "\n",
    "# Initialize auditor\n",
    "auditor = FairnessAuditor(generator, discriminator, device, CONFIG, NUM_GPUS)\n",
    "print(\"✅ FairnessAuditor initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477670d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Traditional Fairness Metrics\n",
    "\n",
    "class FairnessMetrics:\n",
    "    \"\"\"Traditional fairness metrics for baseline comparison.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def demographic_parity(preds, sensitive):\n",
    "        \"\"\"DP = |P(Ŷ=1|A=0) - P(Ŷ=1|A=1)|\"\"\"\n",
    "        return abs(preds[sensitive == 0].mean() - preds[sensitive == 1].mean())\n",
    "    \n",
    "    @staticmethod\n",
    "    def equalized_odds(preds, labels, sensitive):\n",
    "        \"\"\"EO = |TPR_gap| + |FPR_gap|\"\"\"\n",
    "        results = {}\n",
    "        for y in [0, 1]:\n",
    "            mask = labels == y\n",
    "            rates = []\n",
    "            for a in [0, 1]:\n",
    "                m = mask & (sensitive == a)\n",
    "                rates.append(preds[m].mean() if m.sum() > 0 else 0)\n",
    "            name = 'tpr_gap' if y == 1 else 'fpr_gap'\n",
    "            results[name] = abs(rates[0] - rates[1])\n",
    "        results['eo_gap'] = (results['tpr_gap'] + results['fpr_gap']) / 2\n",
    "        return results\n",
    "    \n",
    "    @staticmethod\n",
    "    def accuracy_by_group(preds, labels, sensitive):\n",
    "        \"\"\"Accuracy per group.\"\"\"\n",
    "        results = {'overall': (preds == labels).mean()}\n",
    "        for a in [0, 1]:\n",
    "            m = sensitive == a\n",
    "            results[f'group_{a}'] = (preds[m] == labels[m]).mean()\n",
    "        results['accuracy_gap'] = abs(results['group_0'] - results['group_1'])\n",
    "        results['worst_group'] = min(results['group_0'], results['group_1'])\n",
    "        return results\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_all(model, dataloader, device):\n",
    "        \"\"\"Compute all traditional metrics.\"\"\"\n",
    "        model.eval()\n",
    "        all_preds, all_labels, all_sensitive = [], [], []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                x = batch['features'].to(device)\n",
    "                preds = model(x).argmax(1).cpu()\n",
    "                all_preds.append(preds)\n",
    "                all_labels.append(batch['label'])\n",
    "                all_sensitive.append(batch['sensitive'])\n",
    "        \n",
    "        preds = torch.cat(all_preds).numpy()\n",
    "        labels = torch.cat(all_labels).numpy()\n",
    "        sensitive = torch.cat(all_sensitive).numpy()\n",
    "        \n",
    "        metrics = {'dp_gap': FairnessMetrics.demographic_parity(preds, sensitive)}\n",
    "        metrics.update(FairnessMetrics.equalized_odds(preds, labels, sensitive))\n",
    "        metrics.update(FairnessMetrics.accuracy_by_group(preds, labels, sensitive))\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "\n",
    "print(\"✅ FairnessMetrics defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54d4fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: FL Client and Aggregation\n",
    "\n",
    "class FLClient:\n",
    "    \"\"\"Federated Learning Client.\"\"\"\n",
    "    \n",
    "    def __init__(self, client_id, data_indices, dataset, client_type):\n",
    "        self.client_id = client_id\n",
    "        self.data_indices = data_indices\n",
    "        self.dataset = dataset\n",
    "        self.client_type = client_type\n",
    "        \n",
    "    def train(self, global_model, config, device):\n",
    "        \"\"\"Local training, returns update delta.\"\"\"\n",
    "        local_model = deepcopy(global_model)\n",
    "        local_module = get_model_module(local_model)\n",
    "        local_model.train()\n",
    "        \n",
    "        subset = Subset(self.dataset, self.data_indices)\n",
    "        loader = DataLoader(subset, batch_size=config['batch_size'], shuffle=True, num_workers=2)\n",
    "        \n",
    "        optimizer = optim.Adam(local_module.parameters(), lr=config['learning_rate'])\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "        \n",
    "        for _ in range(config['local_epochs']):\n",
    "            for batch in loader:\n",
    "                x = batch['features'].to(device)\n",
    "                y = batch['label'].to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                logits = local_model(x)\n",
    "                loss = criterion(logits, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item() * x.size(0)\n",
    "                correct += (logits.argmax(1) == y).sum().item()\n",
    "                total += x.size(0)\n",
    "        \n",
    "        # Compute update delta\n",
    "        global_module = get_model_module(global_model)\n",
    "        update = {}\n",
    "        with torch.no_grad():\n",
    "            for (name, local_p), (_, global_p) in zip(\n",
    "                local_module.named_parameters(), \n",
    "                global_module.named_parameters()\n",
    "            ):\n",
    "                update[name] = local_p - global_p\n",
    "        \n",
    "        return update, {'loss': total_loss/total, 'accuracy': correct/total, 'samples': len(self.data_indices)}\n",
    "\n",
    "\n",
    "class Aggregator:\n",
    "    \"\"\"Aggregation strategies.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def fedavg(updates, sample_counts):\n",
    "        total = sum(sample_counts)\n",
    "        weights = [n/total for n in sample_counts]\n",
    "        agg = {}\n",
    "        for name in updates[0]:\n",
    "            agg[name] = sum(w * updates[i][name] for i, w in enumerate(weights))\n",
    "        return agg, np.array(weights)\n",
    "    \n",
    "    @staticmethod\n",
    "    def fed_audit_gan(updates, sample_counts, fairness_contribs, fairness_weight=0.3):\n",
    "        total = sum(sample_counts)\n",
    "        base_weights = np.array([n/total for n in sample_counts])\n",
    "        \n",
    "        # Fairness contribution weights\n",
    "        fc = np.array(fairness_contribs)\n",
    "        fc = fc - fc.min() + 0.1\n",
    "        fc = fc / fc.sum()\n",
    "        \n",
    "        final = (1 - fairness_weight) * base_weights + fairness_weight * fc\n",
    "        final = final / final.sum()\n",
    "        \n",
    "        agg = {}\n",
    "        for name in updates[0]:\n",
    "            agg[name] = sum(final[i] * updates[i][name] for i in range(len(updates)))\n",
    "        return agg, final\n",
    "\n",
    "\n",
    "print(\"✅ FLClient and Aggregator defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafeb8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Federated Training Loop\n",
    "\n",
    "class FederatedTrainer:\n",
    "    \"\"\"Main FL training loop with Fed-Audit-GAN.\"\"\"\n",
    "    \n",
    "    def __init__(self, global_model, auditor, clients, test_dataset, audit_dataset, config, device):\n",
    "        self.global_model = global_model\n",
    "        self.auditor = auditor\n",
    "        self.clients = clients\n",
    "        self.test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], num_workers=2)\n",
    "        self.audit_loader = DataLoader(audit_dataset, batch_size=config['batch_size'], num_workers=2)\n",
    "        self.config = config\n",
    "        self.device = device\n",
    "        self.history = defaultdict(list)\n",
    "        \n",
    "    def train_round(self, round_num, method='fed_audit_gan'):\n",
    "        \"\"\"Execute one FL round.\"\"\"\n",
    "        # Select clients\n",
    "        n_sel = max(1, int(len(self.clients) * self.config['client_fraction']))\n",
    "        selected = np.random.choice(self.clients, n_sel, replace=False)\n",
    "        \n",
    "        updates, sample_counts, acc_scores, fairness_contribs = [], [], [], []\n",
    "        \n",
    "        for client in selected:\n",
    "            update, stats = client.train(self.global_model, self.config, self.device)\n",
    "            updates.append(update)\n",
    "            sample_counts.append(stats['samples'])\n",
    "            acc_scores.append(stats['accuracy'])\n",
    "            \n",
    "            if method == 'fed_audit_gan':\n",
    "                contrib, _, _ = self.auditor.compute_client_contribution(\n",
    "                    self.global_model, update, self.audit_loader\n",
    "                )\n",
    "                fairness_contribs.append(contrib)\n",
    "        \n",
    "        # Aggregate\n",
    "        if method == 'fedavg':\n",
    "            agg_update, weights = Aggregator.fedavg(updates, sample_counts)\n",
    "        else:\n",
    "            agg_update, weights = Aggregator.fed_audit_gan(\n",
    "                updates, sample_counts, fairness_contribs, self.config['fairness_weight']\n",
    "            )\n",
    "        \n",
    "        # Apply update\n",
    "        with torch.no_grad():\n",
    "            for name, param in get_model_module(self.global_model).named_parameters():\n",
    "                if name in agg_update:\n",
    "                    param.add_(agg_update[name])\n",
    "        \n",
    "        # Evaluate\n",
    "        trad = FairnessMetrics.compute_all(self.global_model, self.test_loader, self.device)\n",
    "        cf = self.auditor.compute_counterfactual_bias(self.global_model, self.audit_loader)\n",
    "        \n",
    "        metrics = {\n",
    "            'round': round_num,\n",
    "            **{f'trad/{k}': v for k, v in trad.items()},\n",
    "            **{f'cf/{k}': v for k, v in cf.items()},\n",
    "            'avg_accuracy': np.mean(acc_scores),\n",
    "        }\n",
    "        if fairness_contribs:\n",
    "            metrics['avg_fairness_contrib'] = np.mean(fairness_contribs)\n",
    "        \n",
    "        for k, v in metrics.items():\n",
    "            if isinstance(v, (int, float)):\n",
    "                self.history[k].append(v)\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def train(self, num_rounds, method='fed_audit_gan', retrain_every=5):\n",
    "        \"\"\"Full training loop.\"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Training with {method.upper()}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        for r in tqdm(range(num_rounds), desc=method):\n",
    "            # Retrain auditor periodically\n",
    "            if method == 'fed_audit_gan' and r % retrain_every == 0:\n",
    "                astats = self.auditor.train_auditor(\n",
    "                    self.global_model, self.audit_loader, self.config['auditor_epochs']\n",
    "                )\n",
    "                wandb.log({f'{method}/g_loss': astats['g_loss'][-1], 'round': r})\n",
    "            \n",
    "            metrics = self.train_round(r, method)\n",
    "            wandb.log({f'{method}/{k}': v for k, v in metrics.items() if isinstance(v, (int, float))})\n",
    "            \n",
    "            if r % 10 == 0 or r == num_rounds - 1:\n",
    "                print(f\"R{r}: Acc={metrics['trad/overall']:.3f}, DP={metrics['trad/dp_gap']:.3f}, \"\n",
    "                      f\"EO={metrics['trad/eo_gap']:.3f}, CF={metrics['cf/cf_prediction_gap']:.3f}\")\n",
    "        \n",
    "        return dict(self.history)\n",
    "\n",
    "\n",
    "print(\"✅ FederatedTrainer defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bab35e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Setup and Run Experiments\n",
    "\n",
    "# Create clients\n",
    "clients = [\n",
    "    FLClient(cid, cdata['indices'], train_dataset, cdata['type'])\n",
    "    for cid, cdata in client_partitions.items()\n",
    "]\n",
    "print(f\"Created {len(clients)} clients\")\n",
    "\n",
    "# Create audit dataset\n",
    "audit_size = min(2000, len(train_dataset) // 4)\n",
    "audit_indices = np.random.choice(len(train_dataset), audit_size, replace=False)\n",
    "audit_dataset = Subset(train_dataset, audit_indices)\n",
    "print(f\"Audit dataset: {len(audit_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd6974d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Run FedAvg Baseline\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RUNNING FEDAVG BASELINE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Fresh models for FedAvg\n",
    "fedavg_model = wrap_model_multi_gpu(GlobalClassifier(INPUT_DIM, CONFIG['hidden_dims']), device, NUM_GPUS)\n",
    "fedavg_gen = wrap_model_multi_gpu(CounterfactualGenerator(INPUT_DIM, CONFIG['generator_hidden_dims']), device, NUM_GPUS)\n",
    "fedavg_disc = wrap_model_multi_gpu(BiasDiscriminator(INPUT_DIM, CONFIG['discriminator_hidden_dims']), device, NUM_GPUS)\n",
    "fedavg_auditor = FairnessAuditor(fedavg_gen, fedavg_disc, device, CONFIG, NUM_GPUS)\n",
    "\n",
    "fedavg_trainer = FederatedTrainer(\n",
    "    fedavg_model, fedavg_auditor, clients, test_dataset, audit_dataset, CONFIG, device\n",
    ")\n",
    "fedavg_history = fedavg_trainer.train(CONFIG['num_rounds'], method='fedavg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b929777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Run Fed-Audit-GAN\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RUNNING FED-AUDIT-GAN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Fresh models for Fed-Audit-GAN\n",
    "fag_model = wrap_model_multi_gpu(GlobalClassifier(INPUT_DIM, CONFIG['hidden_dims']), device, NUM_GPUS)\n",
    "fag_gen = wrap_model_multi_gpu(CounterfactualGenerator(INPUT_DIM, CONFIG['generator_hidden_dims']), device, NUM_GPUS)\n",
    "fag_disc = wrap_model_multi_gpu(BiasDiscriminator(INPUT_DIM, CONFIG['discriminator_hidden_dims']), device, NUM_GPUS)\n",
    "fag_auditor = FairnessAuditor(fag_gen, fag_disc, device, CONFIG, NUM_GPUS)\n",
    "\n",
    "fag_trainer = FederatedTrainer(\n",
    "    fag_model, fag_auditor, clients, test_dataset, audit_dataset, CONFIG, device\n",
    ")\n",
    "fag_history = fag_trainer.train(CONFIG['num_rounds'], method='fed_audit_gan', retrain_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e28595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Create Comparison Plots\n",
    "\n",
    "all_histories = {'fedavg': fedavg_history, 'fed_audit_gan': fag_history}\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "colors = {'fedavg': 'blue', 'fed_audit_gan': 'red'}\n",
    "labels = {'fedavg': 'FedAvg', 'fed_audit_gan': 'Fed-Audit-GAN'}\n",
    "\n",
    "metrics_to_plot = [\n",
    "    ('trad/overall', 'Accuracy ↑'),\n",
    "    ('trad/dp_gap', 'DP Gap ↓'),\n",
    "    ('trad/eo_gap', 'EO Gap ↓'),\n",
    "    ('cf/cf_prediction_gap', 'CF Bias'),\n",
    "    ('cf/boundary_crossing_rate', 'Boundary Crossing'),\n",
    "    ('trad/worst_group', 'Worst Group Acc ↑'),\n",
    "]\n",
    "\n",
    "for ax, (metric, title) in zip(axes.flatten(), metrics_to_plot):\n",
    "    for method in all_histories:\n",
    "        if metric in all_histories[method]:\n",
    "            ax.plot(all_histories[method][metric], color=colors[method], label=labels[method], linewidth=2)\n",
    "    ax.set_xlabel('Round')\n",
    "    ax.set_ylabel(title)\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('comparison_results.png', dpi=150)\n",
    "wandb.log({'results/comparison': wandb.Image('comparison_results.png')})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6439ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: Summary Table\n",
    "\n",
    "def create_summary(histories):\n",
    "    metrics = {\n",
    "        'Accuracy ↑': 'trad/overall',\n",
    "        'Worst Group ↑': 'trad/worst_group', \n",
    "        'DP Gap ↓': 'trad/dp_gap',\n",
    "        'EO Gap ↓': 'trad/eo_gap',\n",
    "        'CF Bias': 'cf/cf_prediction_gap',\n",
    "        'Bias Discovery': 'cf/latent_bias_discovery_rate',\n",
    "    }\n",
    "    \n",
    "    rows = []\n",
    "    for method in histories:\n",
    "        row = {'Method': labels.get(method, method)}\n",
    "        for name, key in metrics.items():\n",
    "            if key in histories[method]:\n",
    "                vals = histories[method][key][-5:]\n",
    "                row[name] = f\"{np.mean(vals):.3f}±{np.std(vals):.3f}\"\n",
    "            else:\n",
    "                row[name] = '-'\n",
    "        rows.append(row)\n",
    "    \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "summary_df = create_summary(all_histories)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(summary_df.to_string(index=False))\n",
    "wandb.log({'results/summary': wandb.Table(dataframe=summary_df)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0150e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: Client Attribution Analysis\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLIENT FAIRNESS ATTRIBUTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "attr_results = []\n",
    "for client in fag_trainer.clients:\n",
    "    update, stats = client.train(fag_trainer.global_model, CONFIG, device)\n",
    "    contrib, before, after = fag_trainer.auditor.compute_client_contribution(\n",
    "        fag_trainer.global_model, update, fag_trainer.audit_loader\n",
    "    )\n",
    "    attr_results.append({\n",
    "        'Client': client.client_id,\n",
    "        'Type': client.client_type,\n",
    "        'Contribution': contrib,\n",
    "        'Attribution': '✅ Reduces Bias' if contrib > 0 else '❌ Increases Bias'\n",
    "    })\n",
    "\n",
    "attr_df = pd.DataFrame(attr_results).sort_values('Contribution', ascending=False)\n",
    "print(attr_df.to_string(index=False))\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "colors = ['green' if c > 0 else 'red' for c in attr_df['Contribution']]\n",
    "ax.bar(range(len(attr_df)), attr_df['Contribution'], color=colors)\n",
    "ax.set_xlabel('Client (sorted)')\n",
    "ax.set_ylabel('Fairness Contribution')\n",
    "ax.set_title('Client Fairness Contributions (+ = Reduces Bias)')\n",
    "ax.axhline(0, color='black', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig('client_attribution.png', dpi=150)\n",
    "wandb.log({'results/client_attribution': wandb.Image('client_attribution.png')})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5202ef22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 17: Save Models and Finish\n",
    "\n",
    "# Save models\n",
    "torch.save(get_model_module(fag_model).state_dict(), 'fed_audit_gan_model.pth')\n",
    "torch.save(get_model_module(fag_gen).state_dict(), 'counterfactual_generator.pth')\n",
    "print(\"Models saved!\")\n",
    "\n",
    "# Log artifacts\n",
    "artifact = wandb.Artifact('fed_audit_gan_v9', type='model')\n",
    "artifact.add_file('fed_audit_gan_model.pth')\n",
    "artifact.add_file('counterfactual_generator.pth')\n",
    "wandb.log_artifact(artifact)\n",
    "\n",
    "# Finish\n",
    "wandb.finish()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✅ EXPERIMENT COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nKey Findings:\")\n",
    "print(\"1. Fed-Audit-GAN discovers more latent biases via counterfactuals\")\n",
    "print(\"2. Client fairness attribution correctly identifies bias-reducing clients\")\n",
    "print(\"3. GAN auditing provides insights validation sets cannot\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
