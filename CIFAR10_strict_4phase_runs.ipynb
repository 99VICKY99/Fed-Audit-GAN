{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f93a4874",
   "metadata": {},
   "source": [
    "# Strict 4-Phase Fed-AuditGAN (CIFAR-10)\n",
    "**Branch:** strict-4-phase\n",
    "\n",
    "This notebook runs FedAvg baseline and Strict Fed-AuditGAN with gamma=2 and gamma=8 using the exact formulas from the specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1068bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision tqdm matplotlib numpy wandb -q\n",
    "print(\"Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00785cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import copy\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import wandb\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ========== GPU Configuration with optimizations ==========\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "NUM_GPUS = torch.cuda.device_count()\n",
    "\n",
    "# Enable cuDNN optimizations\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"Using device: {DEVICE} | GPUs available: {NUM_GPUS}\")\n",
    "\n",
    "# ========== AGGRESSIVE GPU UTILIZATION ==========\n",
    "NUM_WORKERS = 4 if NUM_GPUS > 0 else 0\n",
    "PIN_MEMORY = True if torch.cuda.is_available() else False\n",
    "BATCH_SIZE = 1024 if NUM_GPUS > 1 else 512\n",
    "VAL_BATCH_SIZE = 2048 if NUM_GPUS > 1 else 1024\n",
    "PREFETCH_FACTOR = 4 if NUM_WORKERS > 0 else None\n",
    "GAN_BATCH_SIZE = 512\n",
    "N_PROBES = 2000\n",
    "\n",
    "# Experiment settings\n",
    "N_ROUNDS = 50\n",
    "N_CLIENTS = 20\n",
    "LOCAL_EPOCHS = 3\n",
    "GAN_EPOCHS = 20\n",
    "\n",
    "# CIFAR-10 specific\n",
    "IMG_SHAPE = (3, 32, 32)\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# ========== WandB Configuration ==========\n",
    "USE_WANDB = True  # Set to False to disable WandB logging\n",
    "WANDB_PROJECT = \"Fed-AuditGAN-Strict-CIFAR10\"\n",
    "WANDB_ENTITY = None  # Set your WandB username/team or leave None\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"CIFAR-10 Strict 4-Phase Fed-AuditGAN - GPU OPTIMIZED\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"GPUs: {NUM_GPUS}\")\n",
    "print(f\"Batch Size: {BATCH_SIZE} | Val Batch: {VAL_BATCH_SIZE}\")\n",
    "print(f\"Workers: {NUM_WORKERS} | Probes: {N_PROBES}\")\n",
    "print(f\"Rounds: {N_ROUNDS} | Clients: {N_CLIENTS} | Local Epochs: {LOCAL_EPOCHS}\")\n",
    "print(f\"WandB: {'Enabled' if USE_WANDB else 'Disabled'}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272b608c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== WandB Login ==========\n",
    "if USE_WANDB:\n",
    "    wandb.login()\n",
    "    print(\"WandB logged in successfully!\")\n",
    "else:\n",
    "    print(\"WandB is disabled. Set USE_WANDB = True to enable logging.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112e278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Data Preparation ==========\n",
    "print(\"Pre-loading CIFAR-10 dataset...\")\n",
    "\n",
    "# CIFAR-10 transforms with augmentation for training\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "TRAIN_DATA = datasets.CIFAR10('./data', train=True, download=True, transform=transform_train)\n",
    "TEST_DATA = datasets.CIFAR10('./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "# For GAN training - no augmentation\n",
    "transform_gan = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "GAN_TRAIN_DATA = datasets.CIFAR10('./data', train=True, download=True, transform=transform_gan)\n",
    "\n",
    "# Non-IID partition: each client gets only 1-2 classes (extreme heterogeneity)\n",
    "def partition_non_iid_extreme(dataset, n_clients, classes_per_client=2, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    labels = np.array([dataset[i][1] for i in range(len(dataset))])\n",
    "    class_indices = {c: np.where(labels == c)[0] for c in range(NUM_CLASSES)}\n",
    "    client_data = []\n",
    "    classes_assigned = []\n",
    "    for cid in range(n_clients):\n",
    "        n_classes = np.random.randint(1, classes_per_client + 1)\n",
    "        client_classes = np.random.choice(NUM_CLASSES, n_classes, replace=False)\n",
    "        classes_assigned.append(client_classes.tolist())\n",
    "        client_idx = []\n",
    "        for c in client_classes:\n",
    "            n_samples = len(class_indices[c]) // (n_clients // 2)\n",
    "            start = np.random.randint(0, max(1, len(class_indices[c]) - n_samples))\n",
    "            client_idx.extend(class_indices[c][start:start + n_samples])\n",
    "        np.random.shuffle(client_idx)\n",
    "        client_data.append(np.array(client_idx))\n",
    "    return client_data, classes_assigned\n",
    "\n",
    "CLIENT_IDX, CLIENT_CLASSES = partition_non_iid_extreme(TRAIN_DATA, N_CLIENTS)\n",
    "print(f\"Client data sizes: {[len(idx) for idx in CLIENT_IDX]}\")\n",
    "print(f\"Client classes: {CLIENT_CLASSES}\")\n",
    "\n",
    "# Pre-create DataLoaders with GPU optimizations\n",
    "loader_kwargs = {'num_workers': NUM_WORKERS, 'pin_memory': PIN_MEMORY}\n",
    "if NUM_WORKERS > 0:\n",
    "    loader_kwargs['persistent_workers'] = True\n",
    "    loader_kwargs['prefetch_factor'] = PREFETCH_FACTOR\n",
    "\n",
    "TEST_LOADER = DataLoader(TEST_DATA, batch_size=VAL_BATCH_SIZE, shuffle=False, **loader_kwargs)\n",
    "\n",
    "VAL_IDX = np.random.choice(len(GAN_TRAIN_DATA), 5000, replace=False)\n",
    "VAL_LOADER = DataLoader(Subset(GAN_TRAIN_DATA, VAL_IDX), batch_size=GAN_BATCH_SIZE, shuffle=True, **loader_kwargs)\n",
    "\n",
    "# Client training loaders\n",
    "CLIENT_LOADERS = []\n",
    "for cid in range(N_CLIENTS):\n",
    "    loader = DataLoader(Subset(TRAIN_DATA, CLIENT_IDX[cid]), batch_size=BATCH_SIZE, shuffle=True, **loader_kwargs)\n",
    "    CLIENT_LOADERS.append(loader)\n",
    "\n",
    "# Client evaluation loaders\n",
    "CLIENT_EVAL_LOADERS = []\n",
    "for cid in range(N_CLIENTS):\n",
    "    loader = DataLoader(Subset(TRAIN_DATA, CLIENT_IDX[cid]), batch_size=VAL_BATCH_SIZE, shuffle=False, **loader_kwargs)\n",
    "    CLIENT_EVAL_LOADERS.append(loader)\n",
    "\n",
    "print(\"Data loaders ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd18b527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CNN Model for CIFAR-10 ==========\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.conv4 = nn.Conv2d(256, 512, 3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(512)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(512 * 2 * 2, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))  # 32->16\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))  # 16->8\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))  # 8->4\n",
    "        x = self.pool(F.relu(self.bn4(self.conv4(x))))  # 4->2\n",
    "        x = x.view(-1, 512 * 2 * 2)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        return self.fc2(x)\n",
    "\n",
    "# ========== Fairness Generator (Strict Spec) ==========\n",
    "class FairnessGenerator(nn.Module):\n",
    "    def __init__(self, latent_dim=128, num_classes=10, img_shape=(3, 32, 32)):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.img_shape = img_shape\n",
    "        self.label_emb = nn.Embedding(num_classes, latent_dim)\n",
    "        self.init_size = img_shape[1] // 4  # 8\n",
    "        self.l1 = nn.Linear(latent_dim * 2, 256 * self.init_size ** 2)\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(256, 256, 3, 1, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(256, 128, 3, 1, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(128, img_shape[0], 3, 1, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.delta_net = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, int(np.prod(img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.delta_scale = 0.1\n",
    "\n",
    "    def forward(self, z, labels):\n",
    "        gen_input = torch.cat([z, self.label_emb(labels)], dim=1)\n",
    "        out = self.l1(gen_input)\n",
    "        out = out.view(-1, 256, self.init_size, self.init_size)\n",
    "        x = self.conv_blocks(out)\n",
    "        delta = self.delta_net(z).view(-1, *self.img_shape) * self.delta_scale\n",
    "        x_prime = torch.clamp(x + delta, -1, 1)\n",
    "        return x, x_prime\n",
    "\n",
    "# ========== Discriminator ==========\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_classes=10, img_shape=(3, 32, 32)):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.img_shape = img_shape\n",
    "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(img_shape[0] + num_classes, 64, 3, 2, 1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, 3, 2, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(128, 256, 3, 2, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(256, 512, 3, 2, 1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.fc = nn.Linear(512 * 2 * 2, 1)\n",
    "\n",
    "    def forward(self, img, labels):\n",
    "        label_map = self.label_emb(labels).view(-1, self.num_classes, 1, 1)\n",
    "        label_map = label_map.expand(-1, -1, self.img_shape[1], self.img_shape[2])\n",
    "        out = self.conv(torch.cat([img, label_map], dim=1))\n",
    "        return self.fc(out.view(out.size(0), -1))\n",
    "\n",
    "# ========== Helper Functions ==========\n",
    "def make_parallel(model):\n",
    "    if NUM_GPUS > 1:\n",
    "        return nn.DataParallel(model)\n",
    "    return model\n",
    "\n",
    "def get_base_model(model):\n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        return model.module\n",
    "    return model\n",
    "\n",
    "print(\"Models and helpers defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cc7fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== FAIRNESS METRICS ==========\n",
    "def compute_jfi(performances):\n",
    "    p = np.array(performances)\n",
    "    n = len(p)\n",
    "    if np.sum(p**2) == 0:\n",
    "        return 1.0\n",
    "    return (np.sum(p)**2) / (n * np.sum(p**2))\n",
    "\n",
    "def compute_max_min_fairness(performances):\n",
    "    p = np.array(performances)\n",
    "    if np.max(p) == 0:\n",
    "        return 0.0\n",
    "    return np.min(p) / np.max(p)\n",
    "\n",
    "def compute_fairness_variance(performances):\n",
    "    return np.var(np.array(performances))\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_per_client(model, client_loaders):\n",
    "    model.eval()\n",
    "    client_accuracies = []\n",
    "    with torch.amp.autocast(device_type='cuda', enabled=(DEVICE=='cuda')):\n",
    "        for loader in client_loaders:\n",
    "            correct, total = 0, 0\n",
    "            for d, t in loader:\n",
    "                d, t = d.to(DEVICE, non_blocking=True), t.to(DEVICE, non_blocking=True)\n",
    "                correct += (model(d).argmax(1) == t).sum().item()\n",
    "                total += len(t)\n",
    "            client_accuracies.append(100 * correct / total if total > 0 else 0)\n",
    "    return client_accuracies\n",
    "\n",
    "def compute_all_fairness_metrics(client_accuracies):\n",
    "    return {\n",
    "        'jfi': compute_jfi(client_accuracies),\n",
    "        'max_min_fairness': compute_max_min_fairness(client_accuracies),\n",
    "        'fairness_variance': compute_fairness_variance(client_accuracies),\n",
    "        'min_accuracy': np.min(client_accuracies),\n",
    "        'max_accuracy': np.max(client_accuracies),\n",
    "        'mean_accuracy': np.mean(client_accuracies)\n",
    "    }\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.amp.autocast(device_type='cuda', enabled=(DEVICE=='cuda')):\n",
    "        for d, t in loader:\n",
    "            d, t = d.to(DEVICE, non_blocking=True), t.to(DEVICE, non_blocking=True)\n",
    "            correct += (model(d).argmax(1) == t).sum().item()\n",
    "            total += len(t)\n",
    "    return 100 * correct / total\n",
    "\n",
    "print(\"Fairness metrics defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f58bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== STRICT 4-PHASE IMPLEMENTATION ==========\n",
    "\n",
    "# --- Phase 2: Train Fairness Generator ---\n",
    "# Loss: L_G = -||Theta(x) - Theta(x')||^2 + lambda1*||x - x'||^2 + lambda2*L_realism\n",
    "def train_fairness_gan(G, D, model, loader, epochs=20, lambda1=1.0, lambda2=1.0):\n",
    "    model.eval()\n",
    "    G = make_parallel(G)\n",
    "    D = make_parallel(D)\n",
    "    \n",
    "    opt_G = optim.Adam(G.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    opt_D = optim.Adam(D.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    bce = nn.BCEWithLogitsLoss()\n",
    "    scaler = torch.amp.GradScaler(device='cuda', enabled=(DEVICE=='cuda'))\n",
    "    \n",
    "    latent_dim = get_base_model(G).latent_dim\n",
    "    num_classes = get_base_model(G).num_classes\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for imgs, labels in loader:\n",
    "            batch_size = imgs.size(0)\n",
    "            real_t = torch.ones(batch_size, 1, device=DEVICE)\n",
    "            fake_t = torch.zeros(batch_size, 1, device=DEVICE)\n",
    "            imgs = imgs.to(DEVICE, non_blocking=True)\n",
    "            labels = labels.to(DEVICE, non_blocking=True)\n",
    "            z = torch.randn(batch_size, latent_dim, device=DEVICE)\n",
    "            gen_labels = torch.randint(0, num_classes, (batch_size,), device=DEVICE)\n",
    "            \n",
    "            # Generator: L_G = -||Theta(x)-Theta(x')||^2 + lambda1*||x-x'||^2 + lambda2*L_realism\n",
    "            opt_G.zero_grad(set_to_none=True)\n",
    "            with torch.amp.autocast(device_type='cuda', enabled=(DEVICE=='cuda')):\n",
    "                x, x_prime = G(z, gen_labels)\n",
    "                with torch.no_grad():\n",
    "                    pred_x, pred_xp = model(x), model(x_prime)\n",
    "                # Term 1: MAXIMIZE prediction difference (negative sign)\n",
    "                pred_diff = -torch.mean((pred_x - pred_xp) ** 2)\n",
    "                # Term 2: MINIMIZE feature difference\n",
    "                feature_diff = lambda1 * torch.mean((x - x_prime) ** 2)\n",
    "                # Term 3: Realism\n",
    "                gan_loss = lambda2 * (bce(D(x, gen_labels), real_t) + bce(D(x_prime, gen_labels), real_t)) / 2\n",
    "                g_loss = pred_diff + feature_diff + gan_loss\n",
    "            scaler.scale(g_loss).backward()\n",
    "            scaler.step(opt_G)\n",
    "            \n",
    "            # Discriminator\n",
    "            opt_D.zero_grad(set_to_none=True)\n",
    "            with torch.amp.autocast(device_type='cuda', enabled=(DEVICE=='cuda')):\n",
    "                x, x_prime = G(z, gen_labels)\n",
    "                d_real = bce(D(imgs, labels), real_t)\n",
    "                d_fake = (bce(D(x.detach(), gen_labels), fake_t) + bce(D(x_prime.detach(), gen_labels), fake_t)) / 2\n",
    "                d_loss = (d_real + d_fake) / 2\n",
    "            scaler.scale(d_loss).backward()\n",
    "            scaler.step(opt_D)\n",
    "            scaler.update()\n",
    "    \n",
    "    return get_base_model(G), get_base_model(D)\n",
    "\n",
    "# --- Phase 3: Compute Bias (EXACT formula) ---\n",
    "# B = (1/|P|) * sum |Theta(x) - Theta(x')|\n",
    "@torch.no_grad()\n",
    "def compute_bias(model, x, x_prime):\n",
    "    model.eval()\n",
    "    with torch.amp.autocast(device_type='cuda', enabled=(DEVICE=='cuda')):\n",
    "        pred_x = model(x)\n",
    "        pred_xp = model(x_prime)\n",
    "    # |Theta(x) - Theta(x')| summed over classes, averaged over probes\n",
    "    return torch.abs(pred_x - pred_xp).sum(dim=1).mean().item()\n",
    "\n",
    "# --- Phase 4: Softmax Aggregation Weights (EXACT formula) ---\n",
    "# alpha_i = exp(gamma * S_i) / sum_j exp(gamma * S_j)\n",
    "def compute_softmax_weights(S_list, gamma):\n",
    "    S_tensor = torch.tensor(S_list, dtype=torch.float32)\n",
    "    scaled = gamma * S_tensor\n",
    "    alphas = F.softmax(scaled, dim=0).tolist()\n",
    "    return alphas\n",
    "\n",
    "print(\"Strict 4-phase functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5e0ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== RUN FEDAVG BASELINE ==========\n",
    "def run_fedavg(n_rounds=N_ROUNDS, n_clients=N_CLIENTS, local_epochs=LOCAL_EPOCHS, lr=0.01, run_name=\"FedAvg\"):\n",
    "    print(f\"FedAvg | Rounds: {n_rounds} | Clients: {n_clients} | GPUs: {NUM_GPUS}\")\n",
    "    \n",
    "    # Initialize WandB run\n",
    "    if USE_WANDB:\n",
    "        wandb.init(\n",
    "            project=WANDB_PROJECT,\n",
    "            entity=WANDB_ENTITY,\n",
    "            name=run_name,\n",
    "            config={\n",
    "                \"method\": \"FedAvg\",\n",
    "                \"n_rounds\": n_rounds,\n",
    "                \"n_clients\": n_clients,\n",
    "                \"local_epochs\": local_epochs,\n",
    "                \"lr\": lr,\n",
    "                \"batch_size\": BATCH_SIZE,\n",
    "                \"dataset\": \"CIFAR-10\",\n",
    "                \"device\": DEVICE,\n",
    "                \"num_gpus\": NUM_GPUS\n",
    "            },\n",
    "            reinit=True\n",
    "        )\n",
    "    \n",
    "    global_model = make_parallel(CNN().to(DEVICE))\n",
    "    scaler = torch.amp.GradScaler(device='cuda', enabled=(DEVICE=='cuda'))\n",
    "    \n",
    "    history = {'accuracy': [], 'jfi': [], 'max_min_fairness': [], 'fairness_variance': [],\n",
    "               'min_accuracy': [], 'max_accuracy': [], 'client_accuracies': []}\n",
    "    \n",
    "    for rnd in tqdm(range(n_rounds), desc=\"FedAvg\"):\n",
    "        updates = []\n",
    "        client_sizes = []\n",
    "        \n",
    "        for cid in range(n_clients):\n",
    "            local = make_parallel(copy.deepcopy(get_base_model(global_model)).to(DEVICE))\n",
    "            before = {k: v.clone() for k, v in global_model.state_dict().items()}\n",
    "            opt = optim.SGD(local.parameters(), lr=lr, momentum=0.9, weight_decay=1e-4)\n",
    "            local.train()\n",
    "            \n",
    "            for _ in range(local_epochs):\n",
    "                for d, t in CLIENT_LOADERS[cid]:\n",
    "                    d, t = d.to(DEVICE, non_blocking=True), t.to(DEVICE, non_blocking=True)\n",
    "                    opt.zero_grad(set_to_none=True)\n",
    "                    with torch.amp.autocast(device_type='cuda', enabled=(DEVICE=='cuda')):\n",
    "                        loss = F.cross_entropy(local(d), t)\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(opt)\n",
    "                    scaler.update()\n",
    "            \n",
    "            after = local.state_dict()\n",
    "            updates.append({k: after[k] - before[k] for k in before})\n",
    "            client_sizes.append(len(CLIENT_IDX[cid]))\n",
    "            del local\n",
    "            if DEVICE == 'cuda': torch.cuda.empty_cache()\n",
    "        \n",
    "        # FedAvg aggregation: weighted by data size\n",
    "        total_size = sum(client_sizes)\n",
    "        alphas = [size / total_size for size in client_sizes]\n",
    "        \n",
    "        sd = global_model.state_dict()\n",
    "        for k in sd:\n",
    "            sd[k] = sd[k] + sum(alphas[i] * updates[i][k] for i in range(n_clients))\n",
    "        global_model.load_state_dict(sd)\n",
    "        \n",
    "        acc = evaluate(global_model, TEST_LOADER)\n",
    "        client_accs = evaluate_per_client(global_model, CLIENT_EVAL_LOADERS)\n",
    "        fairness = compute_all_fairness_metrics(client_accs)\n",
    "        \n",
    "        history['accuracy'].append(acc)\n",
    "        history['jfi'].append(fairness['jfi'])\n",
    "        history['max_min_fairness'].append(fairness['max_min_fairness'])\n",
    "        history['fairness_variance'].append(fairness['fairness_variance'])\n",
    "        history['min_accuracy'].append(fairness['min_accuracy'])\n",
    "        history['max_accuracy'].append(fairness['max_accuracy'])\n",
    "        history['client_accuracies'].append(client_accs)\n",
    "        \n",
    "        # Log to WandB\n",
    "        if USE_WANDB:\n",
    "            log_dict = {\n",
    "                \"round\": rnd + 1,\n",
    "                \"accuracy\": acc,\n",
    "                \"jfi\": fairness['jfi'],\n",
    "                \"max_min_fairness\": fairness['max_min_fairness'],\n",
    "                \"fairness_variance\": fairness['fairness_variance'],\n",
    "                \"min_accuracy\": fairness['min_accuracy'],\n",
    "                \"max_accuracy\": fairness['max_accuracy'],\n",
    "                \"accuracy_gap\": fairness['max_accuracy'] - fairness['min_accuracy']\n",
    "            }\n",
    "            # Log per-client accuracies\n",
    "            for i, c_acc in enumerate(client_accs):\n",
    "                log_dict[f\"client_{i}_accuracy\"] = c_acc\n",
    "            wandb.log(log_dict)\n",
    "    \n",
    "    # Finish WandB run\n",
    "    if USE_WANDB:\n",
    "        wandb.finish()\n",
    "    \n",
    "    print(f\"FedAvg Done | Accuracy: {history['accuracy'][-1]:.2f}% | JFI: {history['jfi'][-1]:.4f}\")\n",
    "    return history\n",
    "\n",
    "print(\"FedAvg function ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91724a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== RUN STRICT FED-AUDITGAN (4-PHASE) ==========\n",
    "def run_strict_fed_audit_gan(gamma, n_rounds=N_ROUNDS, n_clients=N_CLIENTS, local_epochs=LOCAL_EPOCHS, lr=0.01, gan_epochs=GAN_EPOCHS, n_probes=N_PROBES):\n",
    "    print(f\"Strict Fed-AuditGAN | gamma={gamma} | Rounds: {n_rounds} | Clients: {n_clients}\")\n",
    "    \n",
    "    # Initialize WandB run\n",
    "    run_name = f\"Strict-gamma{gamma}\"\n",
    "    if USE_WANDB:\n",
    "        wandb.init(\n",
    "            project=WANDB_PROJECT,\n",
    "            entity=WANDB_ENTITY,\n",
    "            name=run_name,\n",
    "            config={\n",
    "                \"method\": \"Strict-Fed-AuditGAN\",\n",
    "                \"gamma\": gamma,\n",
    "                \"n_rounds\": n_rounds,\n",
    "                \"n_clients\": n_clients,\n",
    "                \"local_epochs\": local_epochs,\n",
    "                \"lr\": lr,\n",
    "                \"gan_epochs\": gan_epochs,\n",
    "                \"n_probes\": n_probes,\n",
    "                \"batch_size\": BATCH_SIZE,\n",
    "                \"dataset\": \"CIFAR-10\",\n",
    "                \"device\": DEVICE,\n",
    "                \"num_gpus\": NUM_GPUS\n",
    "            },\n",
    "            reinit=True\n",
    "        )\n",
    "    \n",
    "    global_model = make_parallel(CNN().to(DEVICE))\n",
    "    scaler = torch.amp.GradScaler(device='cuda', enabled=(DEVICE=='cuda'))\n",
    "    \n",
    "    history = {'accuracy': [], 'bias': [], 'jfi': [], 'max_min_fairness': [], 'fairness_variance': [],\n",
    "               'min_accuracy': [], 'max_accuracy': [], 'client_accuracies': [], 'S_list': [], 'alphas': []}\n",
    "    \n",
    "    for rnd in tqdm(range(n_rounds), desc=f\"gamma={gamma}\"):\n",
    "        # ===== PHASE 1: Local Training =====\n",
    "        # Each client computes delta_w_i = w_after - w_before\n",
    "        updates = []\n",
    "        for cid in range(n_clients):\n",
    "            local = make_parallel(copy.deepcopy(get_base_model(global_model)).to(DEVICE))\n",
    "            before = {k: v.clone() for k, v in global_model.state_dict().items()}\n",
    "            opt = optim.SGD(local.parameters(), lr=lr, momentum=0.9, weight_decay=1e-4)\n",
    "            local.train()\n",
    "            \n",
    "            for _ in range(local_epochs):\n",
    "                for d, t in CLIENT_LOADERS[cid]:\n",
    "                    d, t = d.to(DEVICE, non_blocking=True), t.to(DEVICE, non_blocking=True)\n",
    "                    opt.zero_grad(set_to_none=True)\n",
    "                    with torch.amp.autocast(device_type='cuda', enabled=(DEVICE=='cuda')):\n",
    "                        loss = F.cross_entropy(local(d), t)\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(opt)\n",
    "                    scaler.update()\n",
    "            \n",
    "            after = local.state_dict()\n",
    "            updates.append({k: after[k] - before[k] for k in before})\n",
    "            del local\n",
    "            if DEVICE == 'cuda': torch.cuda.empty_cache()\n",
    "        \n",
    "        # ===== PHASE 2: Server-Side GAN Auditing =====\n",
    "        # Train G to find bias: L_G = -||Theta(x)-Theta(x')||^2 + lambda1*||x-x'||^2 + lambda2*L_realism\n",
    "        G = FairnessGenerator(img_shape=IMG_SHAPE).to(DEVICE)\n",
    "        D = Discriminator(img_shape=IMG_SHAPE).to(DEVICE)\n",
    "        G, D = train_fairness_gan(G, D, global_model, VAL_LOADER, epochs=gan_epochs)\n",
    "        G.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(n_probes, G.latent_dim, device=DEVICE)\n",
    "            lbls = torch.randint(0, NUM_CLASSES, (n_probes,), device=DEVICE)\n",
    "            with torch.amp.autocast(device_type='cuda', enabled=(DEVICE=='cuda')):\n",
    "                G_par = make_parallel(G)\n",
    "                x_p, xp_p = G_par(z, lbls)\n",
    "        \n",
    "        # ===== PHASE 3: Fairness Contribution Scoring =====\n",
    "        # B_base = (1/|P|) * sum |Theta_old(x) - Theta_old(x')|\n",
    "        B_base = compute_bias(global_model, x_p, xp_p)\n",
    "        \n",
    "        S_list = []\n",
    "        for i, upd in enumerate(updates):\n",
    "            # Theta_test_i = Theta_old + delta_w_i\n",
    "            hyp = make_parallel(copy.deepcopy(get_base_model(global_model)).to(DEVICE))\n",
    "            sd = hyp.state_dict()\n",
    "            for k in sd:\n",
    "                if k in upd:\n",
    "                    sd[k] = sd[k] + upd[k]\n",
    "            hyp.load_state_dict(sd)\n",
    "            # B_i = (1/|P|) * sum |Theta_test_i(x) - Theta_test_i(x')|\n",
    "            B_i = compute_bias(hyp, x_p, xp_p)\n",
    "            # S_i = B_base - B_i (positive = reduced bias)\n",
    "            S_i = B_base - B_i\n",
    "            S_list.append(S_i)\n",
    "            del hyp\n",
    "        \n",
    "        del G, D, x_p, xp_p\n",
    "        if DEVICE == 'cuda': torch.cuda.empty_cache()\n",
    "        \n",
    "        # ===== PHASE 4: Rewards & Aggregation =====\n",
    "        # alpha_i = exp(gamma * S_i) / sum_j exp(gamma * S_j)  (Softmax)\n",
    "        alphas = compute_softmax_weights(S_list, gamma)\n",
    "        \n",
    "        # Theta_new = Theta_old + sum alpha_i * delta_w_i\n",
    "        sd = global_model.state_dict()\n",
    "        for k in sd:\n",
    "            sd[k] = sd[k] + sum(alphas[i] * updates[i][k] for i in range(n_clients))\n",
    "        global_model.load_state_dict(sd)\n",
    "        \n",
    "        # Evaluate\n",
    "        acc = evaluate(global_model, TEST_LOADER)\n",
    "        client_accs = evaluate_per_client(global_model, CLIENT_EVAL_LOADERS)\n",
    "        fairness = compute_all_fairness_metrics(client_accs)\n",
    "        \n",
    "        history['accuracy'].append(acc)\n",
    "        history['bias'].append(B_base)\n",
    "        history['jfi'].append(fairness['jfi'])\n",
    "        history['max_min_fairness'].append(fairness['max_min_fairness'])\n",
    "        history['fairness_variance'].append(fairness['fairness_variance'])\n",
    "        history['min_accuracy'].append(fairness['min_accuracy'])\n",
    "        history['max_accuracy'].append(fairness['max_accuracy'])\n",
    "        history['client_accuracies'].append(client_accs)\n",
    "        history['S_list'].append(S_list)\n",
    "        history['alphas'].append(alphas)\n",
    "        \n",
    "        # Log to WandB\n",
    "        if USE_WANDB:\n",
    "            log_dict = {\n",
    "                \"round\": rnd + 1,\n",
    "                \"accuracy\": acc,\n",
    "                \"bias\": B_base,\n",
    "                \"jfi\": fairness['jfi'],\n",
    "                \"max_min_fairness\": fairness['max_min_fairness'],\n",
    "                \"fairness_variance\": fairness['fairness_variance'],\n",
    "                \"min_accuracy\": fairness['min_accuracy'],\n",
    "                \"max_accuracy\": fairness['max_accuracy'],\n",
    "                \"accuracy_gap\": fairness['max_accuracy'] - fairness['min_accuracy']\n",
    "            }\n",
    "            # Log per-client accuracies, scores, and weights\n",
    "            for i in range(n_clients):\n",
    "                log_dict[f\"client_{i}_accuracy\"] = client_accs[i]\n",
    "                log_dict[f\"client_{i}_score\"] = S_list[i]\n",
    "                log_dict[f\"client_{i}_weight\"] = alphas[i]\n",
    "            wandb.log(log_dict)\n",
    "    \n",
    "    # Finish WandB run\n",
    "    if USE_WANDB:\n",
    "        wandb.finish()\n",
    "    \n",
    "    print(f\"gamma={gamma} Done | Accuracy: {history['accuracy'][-1]:.2f}% | JFI: {history['jfi'][-1]:.4f}\")\n",
    "    return history\n",
    "\n",
    "print(\"Strict Fed-AuditGAN function ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94d3b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== RUN ALL EXPERIMENTS ==========\n",
    "results = {}\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('Running FedAvg Baseline')\n",
    "print('='*60)\n",
    "results['FedAvg'] = run_fedavg(n_rounds=N_ROUNDS, n_clients=N_CLIENTS)\n",
    "\n",
    "for gamma in [2, 8]:\n",
    "    print('\\n' + '='*60)\n",
    "    print(f'Running Strict Fed-AuditGAN gamma = {gamma}')\n",
    "    print('='*60)\n",
    "    results[f'gamma{gamma}'] = run_strict_fed_audit_gan(gamma=gamma, n_rounds=N_ROUNDS, n_clients=N_CLIENTS)\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('All experiments complete!')\n",
    "print('='*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d7ca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== VISUALIZATION ==========\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "colors = {'FedAvg': 'black', 'gamma2': 'blue', 'gamma8': 'red'}\n",
    "linestyles = {'FedAvg': '--', 'gamma2': '-', 'gamma8': '-'}\n",
    "rounds = list(range(1, N_ROUNDS + 1))\n",
    "\n",
    "# Plot 1: Global Accuracy\n",
    "for method in results:\n",
    "    axes[0, 0].plot(rounds, results[method]['accuracy'], linestyle=linestyles[method],\n",
    "                    label=method, color=colors[method], linewidth=2)\n",
    "axes[0, 0].set_xlabel('Round'); axes[0, 0].set_ylabel('Accuracy (%)')\n",
    "axes[0, 0].set_title('CIFAR-10: Global Test Accuracy'); axes[0, 0].legend(); axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: JFI\n",
    "for method in results:\n",
    "    axes[0, 1].plot(rounds, results[method]['jfi'], linestyle=linestyles[method],\n",
    "                    label=method, color=colors[method], linewidth=2)\n",
    "axes[0, 1].set_xlabel('Round'); axes[0, 1].set_ylabel('JFI')\n",
    "axes[0, 1].set_title(\"Jain's Fairness Index (higher=fairer)\"); axes[0, 1].legend(); axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Max-Min Fairness\n",
    "for method in results:\n",
    "    axes[0, 2].plot(rounds, results[method]['max_min_fairness'], linestyle=linestyles[method],\n",
    "                    label=method, color=colors[method], linewidth=2)\n",
    "axes[0, 2].set_xlabel('Round'); axes[0, 2].set_ylabel('Min/Max Ratio')\n",
    "axes[0, 2].set_title('Max-Min Fairness (higher=fairer)'); axes[0, 2].legend(); axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Variance\n",
    "for method in results:\n",
    "    axes[1, 0].plot(rounds, results[method]['fairness_variance'], linestyle=linestyles[method],\n",
    "                    label=method, color=colors[method], linewidth=2)\n",
    "axes[1, 0].set_xlabel('Round'); axes[1, 0].set_ylabel('Variance')\n",
    "axes[1, 0].set_title('Per-Client Accuracy Variance (lower=fairer)'); axes[1, 0].legend(); axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 5: Accuracy Gap\n",
    "for method in results:\n",
    "    gap = [results[method]['max_accuracy'][i] - results[method]['min_accuracy'][i] for i in range(len(rounds))]\n",
    "    axes[1, 1].plot(rounds, gap, linestyle=linestyles[method],\n",
    "                    label=method, color=colors[method], linewidth=2)\n",
    "axes[1, 1].set_xlabel('Round'); axes[1, 1].set_ylabel('Gap (%)')\n",
    "axes[1, 1].set_title('Best-Worst Client Gap (lower=fairer)'); axes[1, 1].legend(); axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 6: Final Per-Client Accuracy\n",
    "final_client_accs = {m: results[m]['client_accuracies'][-1] for m in results}\n",
    "x = np.arange(N_CLIENTS)\n",
    "width = 0.25\n",
    "for i, method in enumerate(results):\n",
    "    axes[1, 2].bar(x + i*width, final_client_accs[method], width, label=method, color=colors[method], alpha=0.8)\n",
    "axes[1, 2].set_xlabel('Client ID'); axes[1, 2].set_ylabel('Accuracy (%)')\n",
    "axes[1, 2].set_title(f'Per-Client Accuracy (Round {N_ROUNDS})'); axes[1, 2].legend(); axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('cifar10_strict_4phase_results.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# ========== Log Summary to WandB ==========\n",
    "if USE_WANDB:\n",
    "    # Create a summary run to log comparison plots and tables\n",
    "    wandb.init(\n",
    "        project=WANDB_PROJECT,\n",
    "        entity=WANDB_ENTITY,\n",
    "        name=\"Summary-Comparison\",\n",
    "        config={\"type\": \"summary\"},\n",
    "        reinit=True\n",
    "    )\n",
    "    \n",
    "    # Log the comparison plot\n",
    "    wandb.log({\"comparison_plot\": wandb.Image('cifar10_strict_4phase_results.png')})\n",
    "    \n",
    "    # Create summary table\n",
    "    summary_data = []\n",
    "    for method in results:\n",
    "        summary_data.append([\n",
    "            method,\n",
    "            results[method]['accuracy'][-1],\n",
    "            results[method]['jfi'][-1],\n",
    "            results[method]['max_min_fairness'][-1],\n",
    "            results[method]['fairness_variance'][-1],\n",
    "            results[method]['min_accuracy'][-1],\n",
    "            results[method]['max_accuracy'][-1],\n",
    "            results[method]['max_accuracy'][-1] - results[method]['min_accuracy'][-1]\n",
    "        ])\n",
    "    \n",
    "    summary_table = wandb.Table(\n",
    "        columns=[\"Method\", \"Accuracy\", \"JFI\", \"Max-Min\", \"Variance\", \"Min Acc\", \"Max Acc\", \"Gap\"],\n",
    "        data=summary_data\n",
    "    )\n",
    "    wandb.log({\"summary_table\": summary_table})\n",
    "    wandb.finish()\n",
    "    print(\"Summary logged to WandB!\")\n",
    "\n",
    "# Summary Table\n",
    "print('\\n' + '='*110)\n",
    "print(f'CIFAR-10 STRICT 4-PHASE RESULTS SUMMARY (Round {N_ROUNDS})')\n",
    "print('='*110)\n",
    "print(f\"{'Method':<15} {'Global Acc':>10} {'JFI':>8} {'Max-Min':>10} {'Variance':>12} {'Min Acc':>10} {'Max Acc':>10} {'Gap':>8}\")\n",
    "print('-'*110)\n",
    "for method in results:\n",
    "    acc = results[method]['accuracy'][-1]\n",
    "    jfi = results[method]['jfi'][-1]\n",
    "    mmf = results[method]['max_min_fairness'][-1]\n",
    "    var = results[method]['fairness_variance'][-1]\n",
    "    min_acc = results[method]['min_accuracy'][-1]\n",
    "    max_acc = results[method]['max_accuracy'][-1]\n",
    "    gap = max_acc - min_acc\n",
    "    print(f\"{method:<15} {acc:>10.2f}% {jfi:>8.4f} {mmf:>10.4f} {var:>12.2f} {min_acc:>10.2f}% {max_acc:>10.2f}% {gap:>8.2f}%\")\n",
    "print('='*110)\n",
    "\n",
    "# Bias summary\n",
    "print('\\nBias Summary (Strict Fed-AuditGAN only):')\n",
    "for method in ['gamma2', 'gamma8']:\n",
    "    if method in results and 'bias' in results[method]:\n",
    "        print(f\"  {method}: Final Bias = {results[method]['bias'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a7324e",
   "metadata": {},
   "source": [
    "---\n",
    "# Strict 4-Phase Fed-AuditGAN: Full Formulas\n",
    "\n",
    "## Phase 1: Local Client Training\n",
    "Each client $i$ trains locally and computes the update:\n",
    "$$\\Delta w_i = w_{\\text{after}} - w_{\\text{before}}$$\n",
    "\n",
    "---\n",
    "\n",
    "## Phase 2: Server-Side Generative Auditing (GAN Training)\n",
    "The generator creates counterfactual pairs $(x, x')$ where $x' = x + \\delta$.\n",
    "\n",
    "**Generator Loss:**\n",
    "$$\\mathcal{L}_G = -\\|\\Theta(x) - \\Theta(x')\\|^2 + \\lambda_1 \\|x - x'\\|^2 + \\lambda_2 \\mathcal{L}_{\\text{realism}}$$\n",
    "\n",
    "- **Term 1:** $-\\|\\Theta(x) - \\Theta(x')\\|^2$ → **Maximize** prediction difference (find bias)\n",
    "- **Term 2:** $\\lambda_1 \\|x - x'\\|^2$ → **Minimize** feature difference (keep $x$ and $x'$ similar)\n",
    "- **Term 3:** $\\lambda_2 \\mathcal{L}_{\\text{realism}}$ → Keep generated samples realistic (adversarial loss)\n",
    "\n",
    "---\n",
    "\n",
    "## Phase 3: Fairness Contribution Scoring\n",
    "\n",
    "### Step 1: Measure Baseline Bias\n",
    "$$B_{\\text{base}} = \\frac{1}{|P|} \\sum_{(x,x') \\in P} |\\Theta_{\\text{old}}(x) - \\Theta_{\\text{old}}(x')|$$\n",
    "\n",
    "### Step 2: Hypothetical Application\n",
    "$$\\Theta_{\\text{test}_i} = \\Theta_{\\text{old}} + \\Delta w_i$$\n",
    "\n",
    "### Step 3: Measure Client Bias\n",
    "$$B_i = \\frac{1}{|P|} \\sum_{(x,x') \\in P} |\\Theta_{\\text{test}_i}(x) - \\Theta_{\\text{test}_i}(x')|$$\n",
    "\n",
    "### Step 4: Calculate Fairness Score\n",
    "$$S_i = B_{\\text{base}} - B_i$$\n",
    "\n",
    "- **$S_i > 0$**: Client **reduced** bias ✓ (Good!)\n",
    "- **$S_i < 0$**: Client **increased** bias ✗ (Bad!)\n",
    "\n",
    "---\n",
    "\n",
    "## Phase 4: Rewards and Aggregation\n",
    "\n",
    "### Softmax Aggregation Weights:\n",
    "$$\\alpha_i = \\frac{\\exp(\\gamma \\cdot S_i)}{\\sum_{j=1}^{K} \\exp(\\gamma \\cdot S_j)}$$\n",
    "\n",
    "- **$\\gamma$ (gamma)**: Scaling factor\n",
    "  - Higher $\\gamma$ → **Strongly punish** biased clients (more extreme weight differences)\n",
    "  - Lower $\\gamma$ → More uniform weighting\n",
    "\n",
    "### Final Aggregation:\n",
    "$$\\Theta_{\\text{new}} = \\Theta_{\\text{old}} + \\sum_{i=1}^{K} \\alpha_i \\cdot \\Delta w_i$$\n",
    "\n",
    "---\n",
    "\n",
    "## Summary Table\n",
    "| Phase | Purpose | Key Formula |\n",
    "|-------|---------|-------------|\n",
    "| 1 | Local Training | $\\Delta w_i = w_{\\text{after}} - w_{\\text{before}}$ |\n",
    "| 2 | GAN Auditing | $\\mathcal{L}_G = -\\|\\Theta(x)-\\Theta(x')\\|^2 + \\lambda_1\\|x-x'\\|^2 + \\lambda_2\\mathcal{L}_{\\text{realism}}$ |\n",
    "| 3 | Scoring | $S_i = B_{\\text{base}} - B_i$ |\n",
    "| 4 | Aggregation | $\\alpha_i = \\text{softmax}(\\gamma \\cdot S_i)$, $\\Theta_{\\text{new}} = \\Theta_{\\text{old}} + \\sum \\alpha_i \\Delta w_i$ |"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
