{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bb112e5",
   "metadata": {},
   "source": [
    "# üîß Fed-Audit-GAN v2.0 - MNIST (Multi-Gamma Ablation Study)\n",
    "\n",
    "## üéØ Experiments Run:\n",
    "- **FedAvg** (Œ≥ = 0.0) - Baseline with uniform weights\n",
    "- **Fed-Audit-GAN Œ≥ = 0.3** - Mild fairness weighting\n",
    "- **Fed-Audit-GAN Œ≥ = 0.5** - Moderate fairness weighting\n",
    "- **Fed-Audit-GAN Œ≥ = 0.7** - Strong fairness weighting\n",
    "- **Fed-Audit-GAN Œ≥ = 2.0** - Very strong fairness weighting\n",
    "\n",
    "## üîß Oscillation Fixes Applied:\n",
    "1. **Momentum/EMA (Œ≤=0.8)**: Smooths fairness scores over time\n",
    "2. **Warm-up Period (5 rounds)**: GAN learns before affecting aggregation\n",
    "3. **FedProx (Œº=0.01)**: Prevents client drift with proximal term\n",
    "\n",
    "## üöÄ GPU/TPU Optimizations:\n",
    "- Mixed Precision Training (AMP) for 2x speedup\n",
    "- TPU auto-detection for Google Colab\n",
    "- Optimized DataLoaders with pin_memory & prefetching\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa87794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install and Import Dependencies\n",
    "# !pip install -q torch torchvision tqdm matplotlib numpy wandb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import copy\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================\n",
    "# üöÄ GPU/TPU OPTIMIZATION SETUP\n",
    "# ============================================================\n",
    "\n",
    "# Check for TPU (Google Colab)\n",
    "USE_TPU = False\n",
    "try:\n",
    "    import torch_xla\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    DEVICE = xm.xla_device()\n",
    "    USE_TPU = True\n",
    "    print(\"‚úÖ TPU detected! Using TPU acceleration.\")\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "# Check for GPU if no TPU\n",
    "if not USE_TPU:\n",
    "    if torch.cuda.is_available():\n",
    "        DEVICE = torch.device('cuda')\n",
    "        # Enable TensorFloat-32 for faster computation on Ampere+ GPUs\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "        # Enable cuDNN autotuner for optimized convolutions\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        torch.backends.cudnn.enabled = True\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"‚úÖ GPU detected: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"   CUDA Version: {torch.version.cuda}\")\n",
    "        print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    else:\n",
    "        DEVICE = torch.device('cpu')\n",
    "        print(\"‚ö†Ô∏è  No GPU/TPU detected. Using CPU (training will be slower).\")\n",
    "\n",
    "# Mixed Precision Training (AMP) - for GPU only\n",
    "USE_AMP = torch.cuda.is_available() and not USE_TPU\n",
    "if USE_AMP:\n",
    "    print(\"‚úÖ Mixed Precision Training (AMP) enabled for faster GPU training.\")\n",
    "\n",
    "print(f\"\\nüìç Device: {DEVICE}\")\n",
    "print(f\"   PyTorch: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad5d08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Login to WandB\n",
    "wandb.login()\n",
    "print(\"‚úÖ WandB logged in!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8d3536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# MODEL DEFINITIONS\n",
    "# ============================================================\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \"\"\"Simple CNN for MNIST classification\"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout2(x)\n",
    "        return self.fc2(x)\n",
    "\n",
    "\n",
    "class FairnessGenerator(nn.Module):\n",
    "    \"\"\"Generator that produces paired samples (x, x') for fairness testing\"\"\"\n",
    "    def __init__(self, latent_dim=100, num_classes=10, img_shape=(1, 28, 28)):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.img_shape = img_shape\n",
    "        self.label_emb = nn.Embedding(num_classes, latent_dim)\n",
    "        self.init_size = img_shape[1] // 4\n",
    "        self.l1 = nn.Linear(latent_dim * 2, 128 * self.init_size ** 2)\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(128), nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, 3, 1, 1), nn.BatchNorm2d(128), nn.LeakyReLU(0.2),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, 1, 1), nn.BatchNorm2d(64), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, img_shape[0], 3, 1, 1), nn.Tanh())\n",
    "        self.delta_net = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256), nn.ReLU(),\n",
    "            nn.Linear(256, int(np.prod(img_shape))), nn.Tanh())\n",
    "        self.delta_scale = 0.1\n",
    "\n",
    "    def forward(self, z, labels):\n",
    "        gen_input = torch.cat([z, self.label_emb(labels)], dim=1)\n",
    "        out = self.l1(gen_input).view(-1, 128, self.init_size, self.init_size)\n",
    "        x = self.conv_blocks(out)\n",
    "        delta = self.delta_net(z).view(-1, *self.img_shape) * self.delta_scale\n",
    "        return x, torch.clamp(x + delta, -1, 1)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"Conditional Discriminator for GAN training - outputs logits for BCEWithLogitsLoss\"\"\"\n",
    "    def __init__(self, num_classes=10, img_shape=(1, 28, 28)):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.img_shape = img_shape\n",
    "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(img_shape[0] + num_classes, 16, 3, 2, 1), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(16, 32, 3, 2, 1), nn.BatchNorm2d(32), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(32, 64, 3, 2, 1), nn.BatchNorm2d(64), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, 3, 2, 1), nn.BatchNorm2d(128), nn.LeakyReLU(0.2))\n",
    "        self.fc = nn.Sequential(nn.Linear(128 * 4, 1))  # No Sigmoid - use BCEWithLogitsLoss\n",
    "\n",
    "    def forward(self, img, labels):\n",
    "        label_map = self.label_emb(labels).view(-1, self.num_classes, 1, 1)\n",
    "        label_map = label_map.expand(-1, -1, self.img_shape[1], self.img_shape[2])\n",
    "        out = self.conv(torch.cat([img, label_map], dim=1))\n",
    "        return self.fc(out.view(out.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14aaab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# HELPER FUNCTIONS (WITH GPU/AMP OPTIMIZATIONS)\n",
    "# ============================================================\n",
    "\n",
    "def train_gan(G, D, model, loader, epochs=30, device='cuda', l1=1.0, l2=1.0):\n",
    "    \"\"\"Train the Fairness GAN with optional Mixed Precision\"\"\"\n",
    "    G, D, model = G.to(device), D.to(device), model.to(device)\n",
    "    model.eval()\n",
    "    opt_G = optim.Adam(G.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    opt_D = optim.Adam(D.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    bce = nn.BCEWithLogitsLoss()  # Safe for autocast\n",
    "    \n",
    "    # Mixed precision scalers (only for GPU)\n",
    "    use_amp_local = USE_AMP and 'cuda' in str(device)\n",
    "    if use_amp_local:\n",
    "        scaler_G = torch.amp.GradScaler(device='cuda')\n",
    "        scaler_D = torch.amp.GradScaler(device='cuda')\n",
    "    \n",
    "    for _ in range(epochs):\n",
    "        for imgs, labels in loader:\n",
    "            bs = imgs.size(0)\n",
    "            real, fake_t = torch.ones(bs, 1, device=device), torch.zeros(bs, 1, device=device)\n",
    "            imgs, labels = imgs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            z = torch.randn(bs, G.latent_dim, device=device)\n",
    "            gl = torch.randint(0, G.num_classes, (bs,), device=device)\n",
    "            \n",
    "            # Generator training with AMP\n",
    "            opt_G.zero_grad(set_to_none=True)\n",
    "            if use_amp_local:\n",
    "                with torch.amp.autocast(device_type='cuda'):\n",
    "                    x, xp = G(z, gl)\n",
    "                    with torch.no_grad():\n",
    "                        px, pxp = model(x), model(xp)\n",
    "                    t1 = -torch.mean((px - pxp) ** 2)\n",
    "                    t2 = l1 * torch.mean((x - xp) ** 2)\n",
    "                    t3 = l2 * (bce(D(x, gl), real) + bce(D(xp, gl), real)) / 2\n",
    "                    g_loss = t1 + t2 + t3\n",
    "                scaler_G.scale(g_loss).backward()\n",
    "                scaler_G.step(opt_G)\n",
    "                scaler_G.update()\n",
    "            else:\n",
    "                x, xp = G(z, gl)\n",
    "                with torch.no_grad():\n",
    "                    px, pxp = model(x), model(xp)\n",
    "                t1 = -torch.mean((px - pxp) ** 2)\n",
    "                t2 = l1 * torch.mean((x - xp) ** 2)\n",
    "                t3 = l2 * (bce(D(x, gl), real) + bce(D(xp, gl), real)) / 2\n",
    "                (t1 + t2 + t3).backward()\n",
    "                opt_G.step()\n",
    "            \n",
    "            # Discriminator training with AMP\n",
    "            opt_D.zero_grad(set_to_none=True)\n",
    "            if use_amp_local:\n",
    "                with torch.amp.autocast(device_type='cuda'):\n",
    "                    x, xp = G(z, gl)\n",
    "                    d_loss = (bce(D(imgs, labels), real) + bce(D(x.detach(), gl), fake_t) + bce(D(xp.detach(), gl), fake_t)) / 3\n",
    "                scaler_D.scale(d_loss).backward()\n",
    "                scaler_D.step(opt_D)\n",
    "                scaler_D.update()\n",
    "            else:\n",
    "                x, xp = G(z, gl)\n",
    "                d_loss = (bce(D(imgs, labels), real) + bce(D(x.detach(), gl), fake_t) + bce(D(xp.detach(), gl), fake_t)) / 3\n",
    "                d_loss.backward()\n",
    "                opt_D.step()\n",
    "    \n",
    "    return G, D\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_bias(model, x, xp, device):\n",
    "    \"\"\"Compute bias as difference in model predictions between x and x'\"\"\"\n",
    "    model.eval()\n",
    "    with torch.amp.autocast(device_type='cuda', enabled=USE_AMP):\n",
    "        return torch.abs(model(x.to(device)) - model(xp.to(device))).sum(1).mean().item()\n",
    "\n",
    "\n",
    "def partition_data_non_iid_unequal(dataset, n_clients, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Create Non-IID partition with UNEQUAL data sizes per client.\n",
    "    Uses Dirichlet distribution for both label and size heterogeneity.\n",
    "    \"\"\"\n",
    "    labels = np.array([dataset[i][1] for i in range(len(dataset))])\n",
    "    n_classes = len(np.unique(labels))\n",
    "    \n",
    "    class_indices = {c: np.where(labels == c)[0] for c in range(n_classes)}\n",
    "    for c in class_indices:\n",
    "        np.random.shuffle(class_indices[c])\n",
    "    \n",
    "    client_indices = [[] for _ in range(n_clients)]\n",
    "    \n",
    "    for c in range(n_classes):\n",
    "        proportions = np.random.dirichlet(np.repeat(alpha, n_clients))\n",
    "        proportions = (proportions * len(class_indices[c])).astype(int)\n",
    "        proportions[-1] = len(class_indices[c]) - proportions[:-1].sum()\n",
    "        \n",
    "        start = 0\n",
    "        for client_id, num_samples in enumerate(proportions):\n",
    "            if num_samples > 0:\n",
    "                client_indices[client_id].extend(\n",
    "                    class_indices[c][start:start + num_samples].tolist()\n",
    "                )\n",
    "            start += num_samples\n",
    "    \n",
    "    result = []\n",
    "    for i in range(n_clients):\n",
    "        indices = np.array(client_indices[i])\n",
    "        np.random.shuffle(indices)\n",
    "        result.append(indices)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device):\n",
    "    \"\"\"Evaluate model accuracy\"\"\"\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.amp.autocast(device_type='cuda', enabled=USE_AMP):\n",
    "        for d, t in loader:\n",
    "            d, t = d.to(device, non_blocking=True), t.to(device, non_blocking=True)\n",
    "            correct += (model(d).argmax(1) == t).sum().item()\n",
    "            total += len(t)\n",
    "    return 100 * correct / total\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_per_client(model, client_loaders, device):\n",
    "    \"\"\"\n",
    "    Evaluate model accuracy on EACH client's data.\n",
    "    This measures how fairly the model performs across clients.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    client_accuracies = []\n",
    "    with torch.amp.autocast(device_type='cuda', enabled=USE_AMP):\n",
    "        for loader in client_loaders:\n",
    "            correct, total = 0, 0\n",
    "            for d, t in loader:\n",
    "                d, t = d.to(device, non_blocking=True), t.to(device, non_blocking=True)\n",
    "                correct += (model(d).argmax(1) == t).sum().item()\n",
    "                total += len(t)\n",
    "            acc = 100 * correct / total if total > 0 else 0\n",
    "            client_accuracies.append(acc)\n",
    "    return client_accuracies\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# FAIRNESS METRICS (Based on Per-Client Performance!)\n",
    "# ============================================================\n",
    "\n",
    "def calculate_jfi(performances):\n",
    "    \"\"\"\n",
    "    Jain's Fairness Index based on CLIENT PERFORMANCES (not weights!)\n",
    "    JFI = (Œ£p·µ¢)¬≤ / (N √ó Œ£p·µ¢¬≤)\n",
    "    Returns 1.0 if all clients have equal performance (perfectly fair)\n",
    "    \"\"\"\n",
    "    p = np.array(performances)\n",
    "    n = len(p)\n",
    "    if np.sum(p ** 2) == 0:\n",
    "        return 1.0\n",
    "    return (np.sum(p) ** 2) / (n * np.sum(p ** 2))\n",
    "\n",
    "\n",
    "def calculate_max_min_fairness(performances):\n",
    "    \"\"\"\n",
    "    Max-Min Fairness: min(acc) / max(acc)\n",
    "    Higher is better (1.0 = all clients have same accuracy)\n",
    "    \"\"\"\n",
    "    p = np.array(performances)\n",
    "    if np.max(p) == 0:\n",
    "        return 0.0\n",
    "    return np.min(p) / np.max(p)\n",
    "\n",
    "\n",
    "def calculate_variance(performances):\n",
    "    \"\"\"Variance of per-client accuracies. Lower is fairer.\"\"\"\n",
    "    return np.var(performances)\n",
    "\n",
    "\n",
    "def calculate_accuracy_gap(performances):\n",
    "    \"\"\"Gap between best and worst client. Lower is fairer.\"\"\"\n",
    "    return np.max(performances) - np.min(performances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfd28b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================\n",
    "\n",
    "# Training Parameters\n",
    "N_ROUNDS = 50           # Total training rounds\n",
    "N_CLIENTS = 20          # Number of federated clients\n",
    "N_GAN_EPOCHS = 20       # GAN training epochs per round\n",
    "N_PROBES = 300          # Number of probe samples\n",
    "LOCAL_EPOCHS = 3        # Local training epochs per client\n",
    "\n",
    "# ‚≠ê MULTI-GAMMA ABLATION STUDY\n",
    "GAMMA_VALUES = [0.0, 0.3, 0.5, 0.7, 2.0]  # 0.0 = FedAvg baseline\n",
    "\n",
    "# ‚≠ê Oscillation Fix Parameters\n",
    "MOMENTUM = 0.8          # EMA momentum for fairness scores (Change 1)\n",
    "WARMUP_ROUNDS = 5       # Rounds before activating fairness scoring (Change 2)\n",
    "MU = 0.01               # FedProx proximal term strength (Change 3)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üîß Fed-Audit-GAN v2.0 - MULTI-GAMMA ABLATION STUDY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Rounds: {N_ROUNDS}, Clients: {N_CLIENTS}\")\n",
    "print(f\"\\nüéØ GAMMA VALUES TO TEST: {GAMMA_VALUES}\")\n",
    "print(f\"   Œ≥=0.0 ‚Üí FedAvg (uniform weights)\")\n",
    "print(f\"   Œ≥=0.3, 0.5, 0.7 ‚Üí Mild fairness weighting\")\n",
    "print(f\"   Œ≥=2.0 ‚Üí Strong fairness weighting\")\n",
    "print(f\"\\n‚≠ê OSCILLATION FIX PARAMETERS:\")\n",
    "print(f\"   Momentum (Œ≤): {MOMENTUM}\")\n",
    "print(f\"   Warm-up Rounds: {WARMUP_ROUNDS}\")\n",
    "print(f\"   FedProx (Œº): {MU}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1d0975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DATA LOADING (WITH GPU OPTIMIZATIONS)\n",
    "# ============================================================\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_data = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create Non-IID partitions with UNEQUAL sizes (Dirichlet distribution)\n",
    "np.random.seed(42)\n",
    "DIRICHLET_ALPHA = 0.5  # Lower = more heterogeneous (0.5 = high imbalance)\n",
    "client_idx = partition_data_non_iid_unequal(train_data, N_CLIENTS, alpha=DIRICHLET_ALPHA)\n",
    "\n",
    "# Calculate data weights for each client (proportional to data size)\n",
    "client_data_sizes = [len(idx) for idx in client_idx]\n",
    "total_samples = sum(client_data_sizes)\n",
    "CLIENT_DATA_WEIGHTS = [size / total_samples for size in client_data_sizes]\n",
    "\n",
    "# ‚ö° DataLoader optimizations for GPU\n",
    "NUM_WORKERS = 2 if torch.cuda.is_available() else 0  # Parallel data loading\n",
    "PIN_MEMORY = torch.cuda.is_available()  # Faster CPU->GPU transfer\n",
    "PREFETCH_FACTOR = 2 if NUM_WORKERS > 0 else None\n",
    "\n",
    "# Create data loaders with optimizations\n",
    "dataloader_kwargs = {\n",
    "    'num_workers': NUM_WORKERS,\n",
    "    'pin_memory': PIN_MEMORY,\n",
    "    'persistent_workers': NUM_WORKERS > 0,\n",
    "}\n",
    "if PREFETCH_FACTOR:\n",
    "    dataloader_kwargs['prefetch_factor'] = PREFETCH_FACTOR\n",
    "\n",
    "test_loader = DataLoader(test_data, batch_size=128, **dataloader_kwargs)  # Larger batch for eval\n",
    "val_loader = DataLoader(Subset(train_data, np.random.choice(len(train_data), 1000, replace=False)), \n",
    "                        batch_size=64, **dataloader_kwargs)\n",
    "\n",
    "# Client data loaders\n",
    "client_loaders = [\n",
    "    DataLoader(Subset(train_data, client_idx[c]), batch_size=64, shuffle=True, **dataloader_kwargs)\n",
    "    for c in range(N_CLIENTS)\n",
    "]\n",
    "\n",
    "print(f\"Training samples: {len(train_data)}\")\n",
    "print(f\"Test samples: {len(test_data)}\")\n",
    "print(f\"\\nüìä NON-IID DATA DISTRIBUTION (Dirichlet Œ±={DIRICHLET_ALPHA}):\")\n",
    "print(f\"   Samples per client: {client_data_sizes}\")\n",
    "print(f\"   Min: {min(client_data_sizes)}, Max: {max(client_data_sizes)}, Ratio: {max(client_data_sizes)/max(1, min(client_data_sizes)):.1f}x\")\n",
    "print(f\"\\n‚öñÔ∏è CLIENT DATA WEIGHTS (for FedAvg):\")\n",
    "for i, (size, weight) in enumerate(zip(client_data_sizes, CLIENT_DATA_WEIGHTS)):\n",
    "    print(f\"   Client {i}: {size:5d} samples ‚Üí weight = {weight:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844aef7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# üöÄ MULTI-GAMMA ABLATION STUDY\n",
    "# Runs: FedAvg (Œ≥=0) + Fed-Audit-GAN with Œ≥=0.3, 0.5, 0.7, 2.0\n",
    "# ============================================================\n",
    "\n",
    "def run_fed_audit_gan(gamma, n_rounds, n_clients, warmup_rounds, momentum, mu,\n",
    "                      train_data, client_idx, val_loader, test_loader, client_loaders,\n",
    "                      n_gan_epochs, n_probes, local_epochs, device, use_amp,\n",
    "                      client_data_weights):\n",
    "    \"\"\"\n",
    "    Run Fed-Audit-GAN v2.0 with specified gamma value.\n",
    "    gamma=0 is equivalent to FedAvg (data-weighted aggregation) - NO GAN training.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize model\n",
    "    model = CNN().to(device)\n",
    "    scaler = torch.amp.GradScaler(device='cuda') if use_amp else None\n",
    "    \n",
    "    # Fairness score history for momentum (only needed for gamma > 0)\n",
    "    fairness_history = {i: 0.0 for i in range(n_clients)}\n",
    "    \n",
    "    # History tracking - NOW BASED ON PER-CLIENT ACCURACY!\n",
    "    history = {\n",
    "        'acc': [], 'bias': [], 'alphas': [],\n",
    "        'raw_scores': [], 'smoothed_scores': [],\n",
    "        'client_accuracies': [],  # Per-client accuracy each round\n",
    "        'jfi': [], 'max_min_fairness': [], 'variance': [], 'accuracy_gap': [],\n",
    "        'min_client_acc': [], 'max_client_acc': []\n",
    "    }\n",
    "    \n",
    "    is_fedavg = (gamma == 0)  # FedAvg mode - skip GAN training\n",
    "    \n",
    "    for rnd in tqdm(range(n_rounds), desc=f\"{'FedAvg' if is_fedavg else f'Œ≥={gamma}'}\"):\n",
    "        # ================================================================\n",
    "        # PHASE 1: Local Client Training (with FedProx + AMP)\n",
    "        # ================================================================\n",
    "        updates = []\n",
    "        global_params = [p.clone().detach() for p in model.parameters()]\n",
    "        \n",
    "        for cid in range(n_clients):\n",
    "            local_model = copy.deepcopy(model)\n",
    "            local_model.train()\n",
    "            before_state = copy.deepcopy(model.state_dict())\n",
    "            optimizer = optim.SGD(local_model.parameters(), lr=0.01, momentum=0.9)\n",
    "            \n",
    "            for epoch in range(local_epochs):\n",
    "                for data, target in client_loaders[cid]:\n",
    "                    data = data.to(device, non_blocking=True)\n",
    "                    target = target.to(device, non_blocking=True)\n",
    "                    optimizer.zero_grad(set_to_none=True)\n",
    "                    \n",
    "                    if use_amp:\n",
    "                        with torch.amp.autocast(device_type='cuda'):\n",
    "                            output = local_model(data)\n",
    "                            ce_loss = F.cross_entropy(output, target)\n",
    "                            prox_loss = sum(((lp - gp) ** 2).sum() \n",
    "                                          for lp, gp in zip(local_model.parameters(), global_params))\n",
    "                            loss = ce_loss + (mu / 2) * prox_loss\n",
    "                        scaler.scale(loss).backward()\n",
    "                        scaler.step(optimizer)\n",
    "                        scaler.update()\n",
    "                    else:\n",
    "                        output = local_model(data)\n",
    "                        ce_loss = F.cross_entropy(output, target)\n",
    "                        prox_loss = sum(((lp - gp) ** 2).sum() \n",
    "                                      for lp, gp in zip(local_model.parameters(), global_params))\n",
    "                        loss = ce_loss + (mu / 2) * prox_loss\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "            \n",
    "            update = {k: local_model.state_dict()[k] - before_state[k] for k in before_state}\n",
    "            updates.append(update)\n",
    "            del local_model\n",
    "            torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "        \n",
    "        # ================================================================\n",
    "        # PHASE 2 & 3: GAN Training + Fairness Scoring (SKIP for FedAvg!)\n",
    "        # ================================================================\n",
    "        B_base = 0.0  # Default bias for FedAvg\n",
    "        S_fair_raw = [0.0] * n_clients\n",
    "        S_fair_smoothed = [0.0] * n_clients\n",
    "        \n",
    "        if not is_fedavg:\n",
    "            # Only train GAN and compute fairness for gamma > 0\n",
    "            G = FairnessGenerator().to(device)\n",
    "            D = Discriminator().to(device)\n",
    "            G, D = train_gan(G, D, model, val_loader, epochs=n_gan_epochs, device=device)\n",
    "            \n",
    "            G.eval()\n",
    "            with torch.no_grad():\n",
    "                z = torch.randn(n_probes, G.latent_dim, device=device)\n",
    "                labels = torch.randint(0, 10, (n_probes,), device=device)\n",
    "                with torch.amp.autocast(device_type='cuda', enabled=use_amp):\n",
    "                    x_probe, xp_probe = G(z, labels)\n",
    "            \n",
    "            # Compute base bias\n",
    "            B_base = compute_bias(model, x_probe, xp_probe, device)\n",
    "            \n",
    "            # Compute fairness scores for each client\n",
    "            S_fair_raw = []\n",
    "            S_fair_smoothed = []\n",
    "            \n",
    "            for cid, upd in enumerate(updates):\n",
    "                hyp_model = copy.deepcopy(model)\n",
    "                hyp_state = hyp_model.state_dict()\n",
    "                for k in hyp_state:\n",
    "                    hyp_state[k] = hyp_state[k] + upd[k]\n",
    "                hyp_model.load_state_dict(hyp_state)\n",
    "                \n",
    "                B_client = compute_bias(hyp_model, x_probe, xp_probe, device)\n",
    "                S_current = B_base - B_client\n",
    "                S_fair_raw.append(S_current)\n",
    "                \n",
    "                # Apply EMA momentum\n",
    "                S_prev = fairness_history[cid]\n",
    "                S_smoothed = (momentum * S_prev) + ((1 - momentum) * S_current)\n",
    "                fairness_history[cid] = S_smoothed\n",
    "                S_fair_smoothed.append(S_smoothed)\n",
    "                del hyp_model\n",
    "            \n",
    "            del G, D, x_probe, xp_probe\n",
    "            torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "        \n",
    "        history['raw_scores'].append(S_fair_raw.copy() if not is_fedavg else [0.0] * n_clients)\n",
    "        history['smoothed_scores'].append(S_fair_smoothed.copy() if not is_fedavg else [0.0] * n_clients)\n",
    "        \n",
    "        # ================================================================\n",
    "        # PHASE 4: Aggregation\n",
    "        # ================================================================\n",
    "        if is_fedavg:\n",
    "            # FedAvg: DATA-WEIGHTED aggregation (proportional to client data size)\n",
    "            alphas = client_data_weights.copy()\n",
    "        elif rnd < warmup_rounds:\n",
    "            # Warm-up: use data-weighted (same as FedAvg)\n",
    "            alphas = client_data_weights.copy()\n",
    "        else:\n",
    "            # Fairness-aware weights (after warm-up)\n",
    "            alphas = F.softmax(torch.tensor(S_fair_smoothed) * gamma, dim=0).tolist()\n",
    "        \n",
    "        # Apply aggregation\n",
    "        new_state = model.state_dict()\n",
    "        for k in new_state:\n",
    "            new_state[k] = new_state[k] + sum(a * u[k] for a, u in zip(alphas, updates))\n",
    "        model.load_state_dict(new_state)\n",
    "        \n",
    "        # ================================================================\n",
    "        # EVALUATION - FAIRNESS BASED ON PER-CLIENT ACCURACY!\n",
    "        # ================================================================\n",
    "        # Global accuracy\n",
    "        acc = evaluate(model, test_loader, device)\n",
    "        \n",
    "        # Per-client accuracy (THIS IS WHAT FAIRNESS IS BASED ON!)\n",
    "        client_accs = evaluate_per_client(model, client_loaders, device)\n",
    "        \n",
    "        # Compute fairness metrics from per-client performance\n",
    "        jfi = calculate_jfi(client_accs)\n",
    "        max_min = calculate_max_min_fairness(client_accs)\n",
    "        var = calculate_variance(client_accs)\n",
    "        gap = calculate_accuracy_gap(client_accs)\n",
    "        \n",
    "        # Store history\n",
    "        history['acc'].append(acc)\n",
    "        history['bias'].append(B_base)\n",
    "        history['alphas'].append(alphas.copy())\n",
    "        history['client_accuracies'].append(client_accs.copy())\n",
    "        history['jfi'].append(jfi)\n",
    "        history['max_min_fairness'].append(max_min)\n",
    "        history['variance'].append(var)\n",
    "        history['accuracy_gap'].append(gap)\n",
    "        history['min_client_acc'].append(min(client_accs))\n",
    "        history['max_client_acc'].append(max(client_accs))\n",
    "        \n",
    "        # Log to WandB\n",
    "        wandb.log({\n",
    "            'round': rnd + 1,\n",
    "            'accuracy': acc,\n",
    "            'bias': B_base,\n",
    "            'jfi': jfi,\n",
    "            'max_min_fairness': max_min,\n",
    "            'fairness_variance': var,\n",
    "            'accuracy_gap': gap,\n",
    "            'min_client_acc': min(client_accs),\n",
    "            'max_client_acc': max(client_accs)\n",
    "        })\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# RUN ALL EXPERIMENTS\n",
    "# ============================================================\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "for gamma in GAMMA_VALUES:\n",
    "    method_name = \"FedAvg\" if gamma == 0 else f\"FedAuditGAN_Œ≥={gamma}\"\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üöÄ RUNNING: {method_name}\")\n",
    "    if gamma == 0:\n",
    "        print(f\"   (Pure FedAvg - NO GAN, data-weighted aggregation)\")\n",
    "    else:\n",
    "        print(f\"   (Fed-Audit-GAN with fairness-aware aggregation)\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Initialize WandB\n",
    "    wandb.init(\n",
    "        project=\"FED_AUDIT_GAN_TEST_1_MNIST\",\n",
    "        name=f\"{method_name}_MNIST_clients{N_CLIENTS}\",\n",
    "        config={\n",
    "            \"method\": method_name,\n",
    "            \"dataset\": \"MNIST\",\n",
    "            \"n_rounds\": N_ROUNDS,\n",
    "            \"n_clients\": N_CLIENTS,\n",
    "            \"gamma\": gamma,\n",
    "            \"momentum\": MOMENTUM,\n",
    "            \"warmup_rounds\": WARMUP_ROUNDS,\n",
    "            \"mu_fedprox\": MU,\n",
    "            \"dirichlet_alpha\": DIRICHLET_ALPHA,\n",
    "            \"device\": str(DEVICE)\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Run experiment\n",
    "    model, history = run_fed_audit_gan(\n",
    "        gamma=gamma,\n",
    "        n_rounds=N_ROUNDS,\n",
    "        n_clients=N_CLIENTS,\n",
    "        warmup_rounds=WARMUP_ROUNDS,\n",
    "        momentum=MOMENTUM,\n",
    "        mu=MU,\n",
    "        train_data=train_data,\n",
    "        client_idx=client_idx,\n",
    "        val_loader=val_loader,\n",
    "        test_loader=test_loader,\n",
    "        client_loaders=client_loaders,\n",
    "        n_gan_epochs=N_GAN_EPOCHS,\n",
    "        n_probes=N_PROBES,\n",
    "        local_epochs=LOCAL_EPOCHS,\n",
    "        device=DEVICE,\n",
    "        use_amp=USE_AMP,\n",
    "        client_data_weights=CLIENT_DATA_WEIGHTS\n",
    "    )\n",
    "    \n",
    "    wandb.finish()\n",
    "    \n",
    "    # Store results\n",
    "    all_results[gamma] = {\n",
    "        'model': model,\n",
    "        'history': history,\n",
    "        'name': method_name\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ {method_name} Complete!\")\n",
    "    print(f\"   Final Accuracy: {history['acc'][-1]:.2f}%\")\n",
    "    print(f\"   Final JFI (per-client): {history['jfi'][-1]:.4f}\")\n",
    "    print(f\"   Accuracy Gap: {history['accuracy_gap'][-1]:.2f}%\")\n",
    "    if gamma > 0:\n",
    "        print(f\"   Final Bias: {history['bias'][-1]:.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ ALL EXPERIMENTS COMPLETE!\")\n",
    "print(\"=\" * 70)\n",
    "print(\"üìä Check your WandB dashboard: https://wandb.ai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e666f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# üìä RESULTS SUMMARY TABLE (Based on Per-Client Accuracy!)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 110)\n",
    "print(\"üìä MULTI-GAMMA ABLATION STUDY RESULTS\")\n",
    "print(\"=\" * 110)\n",
    "\n",
    "print(f\"\\n{'METHOD':<25} {'GLOBAL ACC':<12} {'JFI':<10} {'MAX-MIN':<10} {'GAP':<10} {'MIN ACC':<10} {'MAX ACC':<10}\")\n",
    "print(\"-\" * 110)\n",
    "\n",
    "# Find best metrics\n",
    "best_acc = max(all_results[g]['history']['acc'][-1] for g in GAMMA_VALUES)\n",
    "best_jfi = max(all_results[g]['history']['jfi'][-1] for g in GAMMA_VALUES)\n",
    "lowest_gap = min(all_results[g]['history']['accuracy_gap'][-1] for g in GAMMA_VALUES)\n",
    "\n",
    "for gamma in GAMMA_VALUES:\n",
    "    name = all_results[gamma]['name']\n",
    "    acc = all_results[gamma]['history']['acc'][-1]\n",
    "    jfi = all_results[gamma]['history']['jfi'][-1]\n",
    "    max_min = all_results[gamma]['history']['max_min_fairness'][-1]\n",
    "    gap = all_results[gamma]['history']['accuracy_gap'][-1]\n",
    "    min_acc = all_results[gamma]['history']['min_client_acc'][-1]\n",
    "    max_acc = all_results[gamma]['history']['max_client_acc'][-1]\n",
    "    \n",
    "    acc_mark = \"üèÜ\" if acc == best_acc else \"\"\n",
    "    jfi_mark = \"‚≠ê\" if jfi == best_jfi else \"\"\n",
    "    gap_mark = \"‚úÖ\" if gap == lowest_gap else \"\"\n",
    "    \n",
    "    print(f\"{name:<25} {acc:>8.2f}% {acc_mark:<2} {jfi:>8.4f} {jfi_mark:<2} {max_min:>8.4f}   {gap:>6.2f}% {gap_mark:<2} {min_acc:>8.2f}%  {max_acc:>8.2f}%\")\n",
    "\n",
    "print(\"=\" * 110)\n",
    "\n",
    "# Improvement over FedAvg\n",
    "fedavg_acc = all_results[0.0]['history']['acc'][-1]\n",
    "fedavg_jfi = all_results[0.0]['history']['jfi'][-1]\n",
    "fedavg_gap = all_results[0.0]['history']['accuracy_gap'][-1]\n",
    "\n",
    "print(f\"\\nüìà IMPROVEMENT OVER FedAvg:\")\n",
    "for gamma in GAMMA_VALUES:\n",
    "    if gamma == 0:\n",
    "        continue\n",
    "    name = all_results[gamma]['name']\n",
    "    acc = all_results[gamma]['history']['acc'][-1]\n",
    "    jfi = all_results[gamma]['history']['jfi'][-1]\n",
    "    gap = all_results[gamma]['history']['accuracy_gap'][-1]\n",
    "    \n",
    "    acc_diff = acc - fedavg_acc\n",
    "    jfi_diff = jfi - fedavg_jfi\n",
    "    gap_reduction = fedavg_gap - gap\n",
    "    \n",
    "    print(f\"   {name}:\")\n",
    "    print(f\"      Accuracy: {'+' if acc_diff >= 0 else ''}{acc_diff:.2f}%\")\n",
    "    print(f\"      JFI: {'+' if jfi_diff >= 0 else ''}{jfi_diff:.4f}\")\n",
    "    print(f\"      Gap Reduction: {gap_reduction:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 110)\n",
    "print(\"üìù FAIRNESS METRICS EXPLANATION:\")\n",
    "print(\"   ‚Ä¢ JFI (Jain's Fairness Index): 1.0 = perfect fairness across clients\")\n",
    "print(\"   ‚Ä¢ Max-Min Fairness: min(acc)/max(acc) - higher is fairer\")\n",
    "print(\"   ‚Ä¢ Accuracy Gap: max(acc) - min(acc) - lower is fairer\")\n",
    "print(\"=\" * 110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f11d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# üìä COMPREHENSIVE VISUALIZATION - Per-Client Fairness Metrics\n",
    "# ============================================================\n",
    "\n",
    "# Color palette for different gamma values\n",
    "colors = {\n",
    "    0.0: '#e74c3c',   # Red - FedAvg\n",
    "    0.3: '#f39c12',   # Orange\n",
    "    0.5: '#9b59b6',   # Purple\n",
    "    0.7: '#3498db',   # Blue\n",
    "    2.0: '#2ecc71',   # Green\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "rounds = range(1, N_ROUNDS + 1)\n",
    "\n",
    "# ================================================================\n",
    "# Plot 1: Global Accuracy\n",
    "# ================================================================\n",
    "ax = axes[0, 0]\n",
    "for gamma in GAMMA_VALUES:\n",
    "    name = all_results[gamma]['name']\n",
    "    acc = all_results[gamma]['history']['acc']\n",
    "    linestyle = '--' if gamma == 0 else '-'\n",
    "    ax.plot(rounds, acc, color=colors[gamma], linestyle=linestyle, \n",
    "            marker='o', linewidth=2, markersize=3, label=name)\n",
    "ax.axvspan(1, WARMUP_ROUNDS, alpha=0.15, color='gray', label='Warm-up')\n",
    "ax.set_xlabel('Round', fontsize=12)\n",
    "ax.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "ax.set_title('Global Test Accuracy', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=9, loc='lower right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# ================================================================\n",
    "# Plot 2: JFI (Based on Per-Client Accuracy!)\n",
    "# ================================================================\n",
    "ax = axes[0, 1]\n",
    "for gamma in GAMMA_VALUES:\n",
    "    name = all_results[gamma]['name']\n",
    "    jfi = all_results[gamma]['history']['jfi']\n",
    "    linestyle = '--' if gamma == 0 else '-'\n",
    "    ax.plot(rounds, jfi, color=colors[gamma], linestyle=linestyle,\n",
    "            marker='s', linewidth=2, markersize=3, label=name)\n",
    "ax.axvspan(1, WARMUP_ROUNDS, alpha=0.15, color='gray')\n",
    "ax.set_xlabel('Round', fontsize=12)\n",
    "ax.set_ylabel('JFI', fontsize=12)\n",
    "ax.set_title(\"Jain's Fairness Index (Higher = Fairer)\", fontsize=14, fontweight='bold')\n",
    "ax.set_ylim([0.8, 1.02])\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# ================================================================\n",
    "# Plot 3: Accuracy Gap (Max - Min Client Accuracy)\n",
    "# ================================================================\n",
    "ax = axes[0, 2]\n",
    "for gamma in GAMMA_VALUES:\n",
    "    name = all_results[gamma]['name']\n",
    "    gap = all_results[gamma]['history']['accuracy_gap']\n",
    "    linestyle = '--' if gamma == 0 else '-'\n",
    "    ax.plot(rounds, gap, color=colors[gamma], linestyle=linestyle,\n",
    "            marker='^', linewidth=2, markersize=3, label=name)\n",
    "ax.axvspan(1, WARMUP_ROUNDS, alpha=0.15, color='gray')\n",
    "ax.set_xlabel('Round', fontsize=12)\n",
    "ax.set_ylabel('Accuracy Gap (%)', fontsize=12)\n",
    "ax.set_title('Best-Worst Client Gap (Lower = Fairer)', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# ================================================================\n",
    "# Plot 4: Per-Client Accuracy Variance\n",
    "# ================================================================\n",
    "ax = axes[1, 0]\n",
    "for gamma in GAMMA_VALUES:\n",
    "    name = all_results[gamma]['name']\n",
    "    var = all_results[gamma]['history']['variance']\n",
    "    linestyle = '--' if gamma == 0 else '-'\n",
    "    ax.plot(rounds, var, color=colors[gamma], linestyle=linestyle,\n",
    "            marker='d', linewidth=2, markersize=3, label=name)\n",
    "ax.axvspan(1, WARMUP_ROUNDS, alpha=0.15, color='gray')\n",
    "ax.set_xlabel('Round', fontsize=12)\n",
    "ax.set_ylabel('Variance', fontsize=12)\n",
    "ax.set_title('Per-Client Accuracy Variance (Lower = Fairer)', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# ================================================================\n",
    "# Plot 5: Min & Max Client Accuracy Over Time\n",
    "# ================================================================\n",
    "ax = axes[1, 1]\n",
    "for gamma in GAMMA_VALUES:\n",
    "    name = all_results[gamma]['name']\n",
    "    min_acc = all_results[gamma]['history']['min_client_acc']\n",
    "    max_acc = all_results[gamma]['history']['max_client_acc']\n",
    "    linestyle = '--' if gamma == 0 else '-'\n",
    "    ax.fill_between(rounds, min_acc, max_acc, color=colors[gamma], alpha=0.2)\n",
    "    ax.plot(rounds, min_acc, color=colors[gamma], linestyle=linestyle, linewidth=1.5)\n",
    "    ax.plot(rounds, max_acc, color=colors[gamma], linestyle=linestyle, linewidth=1.5, label=name)\n",
    "ax.axvspan(1, WARMUP_ROUNDS, alpha=0.15, color='gray')\n",
    "ax.set_xlabel('Round', fontsize=12)\n",
    "ax.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "ax.set_title('Min-Max Client Accuracy Range', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# ================================================================\n",
    "# Plot 6: Final Per-Client Accuracy Bar Chart\n",
    "# ================================================================\n",
    "ax = axes[1, 2]\n",
    "x = np.arange(N_CLIENTS)\n",
    "width = 0.15\n",
    "for i, gamma in enumerate(GAMMA_VALUES):\n",
    "    name = all_results[gamma]['name']\n",
    "    client_accs = all_results[gamma]['history']['client_accuracies'][-1]\n",
    "    ax.bar(x + i*width, client_accs, width, label=name, color=colors[gamma], alpha=0.8)\n",
    "ax.set_xlabel('Client ID', fontsize=12)\n",
    "ax.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "ax.set_title(f'Per-Client Accuracy (Final Round)', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=8, loc='lower right')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('multi_gamma_fairness_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìÅ Results saved to: multi_gamma_fairness_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568bd003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# üìä DETAILED ANALYSIS\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìä DETAILED GAMMA ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\"\"\n",
    "üìù INTERPRETATION OF GAMMA (Œ≥) VALUES:\n",
    "\n",
    "   Œ≥ = 0.0 (FedAvg):\n",
    "      - Uniform weights: Œ±_i = 1/N for all clients\n",
    "      - Ignores fairness scores completely\n",
    "      - Baseline for comparison\n",
    "\n",
    "   Œ≥ = 0.3 (Mild Fairness):\n",
    "      - Slight preference for fair clients\n",
    "      - Weights close to uniform\n",
    "      - Minimal oscillation risk\n",
    "\n",
    "   Œ≥ = 0.5 (Moderate Fairness):\n",
    "      - Balanced fairness-accuracy trade-off\n",
    "      - Moderate weight differentiation\n",
    "\n",
    "   Œ≥ = 0.7 (Strong Fairness):\n",
    "      - Stronger preference for fair clients\n",
    "      - More weight variance\n",
    "\n",
    "   Œ≥ = 2.0 (Very Strong Fairness):\n",
    "      - Aggressive fairness weighting\n",
    "      - Large weight differences between clients\n",
    "      - Requires momentum to stabilize\n",
    "\n",
    "üìà KEY METRICS EXPLANATION:\n",
    "\n",
    "   ‚Ä¢ Accuracy: Higher is better (model performance)\n",
    "   ‚Ä¢ Bias: Lower is better (fairness)\n",
    "   ‚Ä¢ JFI: 1.0 = equal weights, <1.0 = differentiated weights\n",
    "   \n",
    "   ‚ö° TRADE-OFF: Lower Œ≥ = more stable, Higher Œ≥ = more fairness-aware\n",
    "\n",
    "üìä OSCILLATION FIX EFFECTIVENESS:\n",
    "   - Momentum (Œ≤={MOMENTUM}) smooths score fluctuations\n",
    "   - Warm-up ({WARMUP_ROUNDS} rounds) lets GAN learn first\n",
    "   - FedProx (Œº={MU}) prevents client drift\n",
    "\"\"\")\n",
    "\n",
    "# Find optimal gamma\n",
    "best_gamma_acc = max(GAMMA_VALUES, key=lambda g: all_results[g]['history']['acc'][-1])\n",
    "best_gamma_bias = min(GAMMA_VALUES, key=lambda g: all_results[g]['history']['bias'][-1])\n",
    "\n",
    "print(f\"\\nüèÜ OPTIMAL GAMMA VALUES:\")\n",
    "print(f\"   Best for Accuracy: Œ≥ = {best_gamma_acc} ({all_results[best_gamma_acc]['history']['acc'][-1]:.2f}%)\")\n",
    "print(f\"   Best for Bias: Œ≥ = {best_gamma_bias} (Bias = {all_results[best_gamma_bias]['history']['bias'][-1]:.6f})\")\n",
    "\n",
    "# Check if there's a clear winner\n",
    "if best_gamma_acc == best_gamma_bias:\n",
    "    print(f\"\\n   ‚úÖ Œ≥ = {best_gamma_acc} is optimal for BOTH accuracy and fairness!\")\n",
    "else:\n",
    "    print(f\"\\n   ‚öñÔ∏è Trade-off exists: Choose based on priority (accuracy vs fairness)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ee7842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SAVE ALL MODELS AND RESULTS\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "\n",
    "# Create results directory\n",
    "os.makedirs('results_v2', exist_ok=True)\n",
    "\n",
    "# Save all models and histories\n",
    "for gamma in GAMMA_VALUES:\n",
    "    name = all_results[gamma]['name']\n",
    "    filename = f\"results_v2/{name.replace('=', '').replace('.', '_')}_MNIST.pth\"\n",
    "    \n",
    "    torch.save({\n",
    "        'model_state_dict': all_results[gamma]['model'].state_dict(),\n",
    "        'history': all_results[gamma]['history'],\n",
    "        'config': {\n",
    "            'n_rounds': N_ROUNDS,\n",
    "            'n_clients': N_CLIENTS,\n",
    "            'gamma': gamma,\n",
    "            'momentum': MOMENTUM,\n",
    "            'warmup_rounds': WARMUP_ROUNDS,\n",
    "            'mu': MU\n",
    "        }\n",
    "    }, filename)\n",
    "    print(f\"‚úÖ Saved: {filename}\")\n",
    "\n",
    "# Save combined results summary\n",
    "import pickle\n",
    "with open('results_v2/all_results_summary.pkl', 'wb') as f:\n",
    "    summary = {\n",
    "        gamma: {\n",
    "            'name': all_results[gamma]['name'],\n",
    "            'history': all_results[gamma]['history'],\n",
    "            'final_acc': all_results[gamma]['history']['acc'][-1],\n",
    "            'final_bias': all_results[gamma]['history']['bias'][-1]\n",
    "        }\n",
    "        for gamma in GAMMA_VALUES\n",
    "    }\n",
    "    pickle.dump(summary, f)\n",
    "print(\"‚úÖ Saved: results_v2/all_results_summary.pkl\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"üìä FINAL RESULTS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "for gamma in GAMMA_VALUES:\n",
    "    name = all_results[gamma]['name']\n",
    "    acc = all_results[gamma]['history']['acc'][-1]\n",
    "    bias = all_results[gamma]['history']['bias'][-1]\n",
    "    print(f\"   {name}: {acc:.2f}% accuracy, {bias:.6f} bias\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nüìä Check WandB dashboard: https://wandb.ai\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
