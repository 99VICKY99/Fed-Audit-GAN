{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ef7174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install packages\n",
    "!pip install -q torch torchvision tqdm matplotlib numpy wandb\n",
    "\n",
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023fb275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Login to WandB\n",
    "import wandb\n",
    "wandb.login()\n",
    "print(\"WandB logged in!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffcf00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Clone repo (REPLACE YOUR_USERNAME)\n",
    "!git clone https://github.com/99VICKY99/Fed-Audit-GAN.git\n",
    "%cd Fed-Audit-GAN\n",
    "!git checkout strict-4-phase\n",
    "!git branch --show-current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5ac9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Complete Training Script with WandB\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import copy\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import pickle\n",
    "import wandb\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout2(x)\n",
    "        return self.fc2(x)\n",
    "\n",
    "class FairnessGenerator(nn.Module):\n",
    "    def __init__(self, latent_dim=100, num_classes=10, img_shape=(1, 28, 28)):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.img_shape = img_shape\n",
    "        self.label_emb = nn.Embedding(num_classes, latent_dim)\n",
    "        self.init_size = img_shape[1] // 4\n",
    "        self.l1 = nn.Linear(latent_dim * 2, 128 * self.init_size ** 2)\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(128), nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, 3, 1, 1), nn.BatchNorm2d(128), nn.LeakyReLU(0.2),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, 1, 1), nn.BatchNorm2d(64), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, img_shape[0], 3, 1, 1), nn.Tanh())\n",
    "        self.delta_net = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256), nn.ReLU(),\n",
    "            nn.Linear(256, int(np.prod(img_shape))), nn.Tanh())\n",
    "        self.delta_scale = 0.1\n",
    "\n",
    "    def forward(self, z, labels):\n",
    "        gen_input = torch.cat([z, self.label_emb(labels)], dim=1)\n",
    "        out = self.l1(gen_input).view(-1, 128, self.init_size, self.init_size)\n",
    "        x = self.conv_blocks(out)\n",
    "        delta = self.delta_net(z).view(-1, *self.img_shape) * self.delta_scale\n",
    "        return x, torch.clamp(x + delta, -1, 1)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_classes=10, img_shape=(1, 28, 28)):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.img_shape = img_shape\n",
    "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(img_shape[0] + num_classes, 16, 3, 2, 1), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(16, 32, 3, 2, 1), nn.BatchNorm2d(32), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(32, 64, 3, 2, 1), nn.BatchNorm2d(64), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, 3, 2, 1), nn.BatchNorm2d(128), nn.LeakyReLU(0.2))\n",
    "        self.fc = nn.Sequential(nn.Linear(128 * 4, 1), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, img, labels):\n",
    "        label_map = self.label_emb(labels).view(-1, self.num_classes, 1, 1)\n",
    "        label_map = label_map.expand(-1, -1, self.img_shape[1], self.img_shape[2])\n",
    "        out = self.conv(torch.cat([img, label_map], dim=1))\n",
    "        return self.fc(out.view(out.size(0), -1))\n",
    "\n",
    "def train_gan(G, D, model, loader, epochs=30, device='cuda', l1=1.0, l2=1.0):\n",
    "    G, D, model = G.to(device), D.to(device), model.to(device)\n",
    "    model.eval()\n",
    "    opt_G = optim.Adam(G.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    opt_D = optim.Adam(D.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    bce = nn.BCELoss()\n",
    "    for _ in range(epochs):\n",
    "        for imgs, labels in loader:\n",
    "            bs = imgs.size(0)\n",
    "            real, fake_t = torch.ones(bs, 1, device=device), torch.zeros(bs, 1, device=device)\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            z = torch.randn(bs, G.latent_dim, device=device)\n",
    "            gl = torch.randint(0, G.num_classes, (bs,), device=device)\n",
    "            x, xp = G(z, gl)\n",
    "            with torch.no_grad():\n",
    "                px, pxp = model(x), model(xp)\n",
    "            t1 = -torch.mean((px - pxp) ** 2)\n",
    "            t2 = l1 * torch.mean((x - xp) ** 2)\n",
    "            t3 = l2 * (bce(D(x, gl), real) + bce(D(xp, gl), real)) / 2\n",
    "            opt_G.zero_grad(); (t1 + t2 + t3).backward(); opt_G.step()\n",
    "            x, xp = G(z, gl)\n",
    "            d_loss = (bce(D(imgs, labels), real) + bce(D(x.detach(), gl), fake_t) + bce(D(xp.detach(), gl), fake_t)) / 3\n",
    "            opt_D.zero_grad(); d_loss.backward(); opt_D.step()\n",
    "    return G, D\n",
    "\n",
    "def compute_bias(model, x, xp, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        return torch.abs(model(x.to(device)) - model(xp.to(device))).sum(1).mean().item()\n",
    "\n",
    "def partition_data(dataset, n):\n",
    "    idx = np.argsort([dataset[i][1] for i in range(len(dataset))])\n",
    "    shards = np.array_split(idx, n * 2)\n",
    "    np.random.shuffle(shards)\n",
    "    return [np.concatenate([shards[2*i], shards[2*i+1]]) for i in range(n)]\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    correct = sum((model(d.to(device)).argmax(1) == t.to(device)).sum().item() for d, t in loader)\n",
    "    return 100 * correct / sum(len(t) for _, t in loader)\n",
    "\n",
    "# Config\n",
    "N_ROUNDS = 10\n",
    "N_CLIENTS = 5\n",
    "GAMMA = 2.0\n",
    "N_GAN_EPOCHS = 20\n",
    "N_PROBES = 300\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Init WandB\n",
    "wandb.init(project=\"fed-audit-gan\", name=f\"colab_gamma{GAMMA}_clients{N_CLIENTS}\", config={\n",
    "    \"n_rounds\": N_ROUNDS, \"n_clients\": N_CLIENTS, \"gamma\": GAMMA, \"device\": DEVICE})\n",
    "\n",
    "# Data\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "train_data = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "client_idx = partition_data(train_data, N_CLIENTS)\n",
    "test_loader = DataLoader(test_data, batch_size=64)\n",
    "val_loader = DataLoader(Subset(train_data, np.random.choice(len(train_data), 1000)), batch_size=32)\n",
    "\n",
    "# Model\n",
    "global_model = CNN().to(DEVICE)\n",
    "history = {'acc': [], 'bias': []}\n",
    "\n",
    "print(f\"Training: {N_ROUNDS} rounds, {N_CLIENTS} clients, gamma={GAMMA}\")\n",
    "for r in range(N_ROUNDS):\n",
    "    print(f\"\\n=== Round {r+1}/{N_ROUNDS} ===\")\n",
    "    \n",
    "    # Phase 1: Client training\n",
    "    updates = []\n",
    "    for c in tqdm(range(N_CLIENTS), desc=\"Phase 1\"):\n",
    "        loader = DataLoader(Subset(train_data, client_idx[c]), batch_size=32, shuffle=True)\n",
    "        local = copy.deepcopy(global_model)\n",
    "        before = copy.deepcopy(global_model.state_dict())\n",
    "        opt = optim.SGD(local.parameters(), lr=0.01)\n",
    "        local.train()\n",
    "        for _ in range(3):\n",
    "            for d, t in loader:\n",
    "                opt.zero_grad()\n",
    "                F.cross_entropy(local(d.to(DEVICE)), t.to(DEVICE)).backward()\n",
    "                opt.step()\n",
    "        updates.append({k: local.state_dict()[k] - before[k] for k in before})\n",
    "    \n",
    "    # Phase 2: GAN\n",
    "    print(\"Phase 2: GAN training\")\n",
    "    G = FairnessGenerator()\n",
    "    D = Discriminator()\n",
    "    G, D = train_gan(G, D, global_model, val_loader, epochs=N_GAN_EPOCHS, device=DEVICE)\n",
    "    G.eval()\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(N_PROBES, G.latent_dim, device=DEVICE)\n",
    "        lbl = torch.randint(0, 10, (N_PROBES,), device=DEVICE)\n",
    "        x, xp = G(z, lbl)\n",
    "    \n",
    "    # Phase 3: Scoring\n",
    "    B_base = compute_bias(global_model, x, xp, DEVICE)\n",
    "    print(f\"Phase 3: B_base={B_base:.4f}\")\n",
    "    S = []\n",
    "    for i, upd in enumerate(updates):\n",
    "        hyp = copy.deepcopy(global_model)\n",
    "        sd = hyp.state_dict()\n",
    "        for k in sd: sd[k] = sd[k] + upd[k]\n",
    "        hyp.load_state_dict(sd)\n",
    "        B_i = compute_bias(hyp, x, xp, DEVICE)\n",
    "        S.append(B_base - B_i)\n",
    "        print(f\"  Client {i}: S={S[-1]:+.4f}\")\n",
    "    \n",
    "    # Phase 4: Aggregation\n",
    "    alpha = F.softmax(torch.tensor(S) * GAMMA, dim=0).tolist()\n",
    "    print(f\"Phase 4: alpha={[f'{a:.3f}' for a in alpha]}\")\n",
    "    sd = global_model.state_dict()\n",
    "    for k in sd:\n",
    "        sd[k] = sd[k] + sum(a * u[k] for a, u in zip(alpha, updates))\n",
    "    global_model.load_state_dict(sd)\n",
    "    \n",
    "    acc = evaluate(global_model, test_loader, DEVICE)\n",
    "    history['acc'].append(acc)\n",
    "    history['bias'].append(B_base)\n",
    "    wandb.log({'round': r+1, 'accuracy': acc, 'bias': B_base, 'avg_S': np.mean(S)})\n",
    "    print(f\"Accuracy: {acc:.2f}%\")\n",
    "\n",
    "print(f\"\\nFinal: {history['acc'][-1]:.2f}%\")\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257df508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BASELINE: Standard FedAvg (No Fairness-Aware Aggregation)\n",
    "# ============================================================\n",
    "# This runs the SAME setup but with uniform weights (Î³ = 0 equivalent)\n",
    "# Formula: Î±_i = 1/N for all clients (standard FedAvg)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import copy\n",
    "from tqdm.notebook import tqdm\n",
    "import wandb\n",
    "\n",
    "# Reuse same CNN, Generator, Discriminator from above\n",
    "# Just redefine to ensure they're available\n",
    "\n",
    "class CNN_Baseline(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNN_Baseline, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout2(x)\n",
    "        return self.fc2(x)\n",
    "\n",
    "def evaluate_baseline(model, loader, device):\n",
    "    model.eval()\n",
    "    correct = sum((model(d.to(device)).argmax(1) == t.to(device)).sum().item() for d, t in loader)\n",
    "    return 100 * correct / sum(len(t) for _, t in loader)\n",
    "\n",
    "def compute_bias_baseline(model, x, xp, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        return torch.abs(model(x.to(device)) - model(xp.to(device))).sum(1).mean().item()\n",
    "\n",
    "# Same config as Fed-Audit-GAN for fair comparison\n",
    "N_ROUNDS_BASE = N_ROUNDS  # Use same as above\n",
    "N_CLIENTS_BASE = N_CLIENTS\n",
    "DEVICE_BASE = DEVICE\n",
    "\n",
    "# Initialize WandB for FedAvg\n",
    "wandb.init(project=\"fed-audit-gan\", name=f\"FedAvg_baseline_clients{N_CLIENTS_BASE}\", config={\n",
    "    \"method\": \"FedAvg\",\n",
    "    \"n_rounds\": N_ROUNDS_BASE, \n",
    "    \"n_clients\": N_CLIENTS_BASE,\n",
    "    \"gamma\": 0,  # No fairness weighting\n",
    "    \"device\": DEVICE_BASE\n",
    "})\n",
    "\n",
    "# Use same data partition for fair comparison\n",
    "transform_base = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "train_data_base = datasets.MNIST('./data', train=True, download=True, transform=transform_base)\n",
    "test_data_base = datasets.MNIST('./data', train=False, download=True, transform=transform_base)\n",
    "\n",
    "# Same partition function\n",
    "def partition_data_base(dataset, n):\n",
    "    idx = np.argsort([dataset[i][1] for i in range(len(dataset))])\n",
    "    shards = np.array_split(idx, n * 2)\n",
    "    np.random.seed(42)  # Same seed for reproducibility\n",
    "    np.random.shuffle(shards)\n",
    "    return [np.concatenate([shards[2*i], shards[2*i+1]]) for i in range(n)]\n",
    "\n",
    "client_idx_base = partition_data_base(train_data_base, N_CLIENTS_BASE)\n",
    "test_loader_base = DataLoader(test_data_base, batch_size=64)\n",
    "val_loader_base = DataLoader(Subset(train_data_base, np.random.choice(len(train_data_base), 1000)), batch_size=32)\n",
    "\n",
    "# Initialize model\n",
    "global_model_fedavg = CNN_Baseline().to(DEVICE_BASE)\n",
    "\n",
    "# History for FedAvg\n",
    "history_fedavg = {'acc': [], 'bias': []}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"BASELINE: Standard FedAvg (Uniform Weights)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Rounds: {N_ROUNDS_BASE}, Clients: {N_CLIENTS_BASE}\")\n",
    "print(\"Aggregation: Î±_i = 1/N (equal weights for all clients)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Reuse Generator for bias measurement (same as Fed-Audit-GAN)\n",
    "G_base = FairnessGenerator()\n",
    "D_base = Discriminator()\n",
    "G_base, D_base = train_gan(G_base, D_base, global_model_fedavg, val_loader_base, epochs=N_GAN_EPOCHS, device=DEVICE_BASE)\n",
    "G_base.eval()\n",
    "with torch.no_grad():\n",
    "    z_base = torch.randn(N_PROBES, G_base.latent_dim, device=DEVICE_BASE)\n",
    "    lbl_base = torch.randint(0, 10, (N_PROBES,), device=DEVICE_BASE)\n",
    "    x_base, xp_base = G_base(z_base, lbl_base)\n",
    "\n",
    "for r in range(N_ROUNDS_BASE):\n",
    "    print(f\"\\n=== FedAvg Round {r+1}/{N_ROUNDS_BASE} ===\")\n",
    "    \n",
    "    # Phase 1: Client training (same as Fed-Audit-GAN)\n",
    "    updates_base = []\n",
    "    for c in tqdm(range(N_CLIENTS_BASE), desc=\"Client Training\"):\n",
    "        loader = DataLoader(Subset(train_data_base, client_idx_base[c]), batch_size=32, shuffle=True)\n",
    "        local = copy.deepcopy(global_model_fedavg)\n",
    "        before = copy.deepcopy(global_model_fedavg.state_dict())\n",
    "        opt = optim.SGD(local.parameters(), lr=0.01)\n",
    "        local.train()\n",
    "        for _ in range(3):\n",
    "            for d, t in loader:\n",
    "                opt.zero_grad()\n",
    "                F.cross_entropy(local(d.to(DEVICE_BASE)), t.to(DEVICE_BASE)).backward()\n",
    "                opt.step()\n",
    "        updates_base.append({k: local.state_dict()[k] - before[k] for k in before})\n",
    "    \n",
    "    # Measure bias for comparison\n",
    "    B_base_fedavg = compute_bias_baseline(global_model_fedavg, x_base, xp_base, DEVICE_BASE)\n",
    "    print(f\"  Bias (B_base): {B_base_fedavg:.4f}\")\n",
    "    \n",
    "    # FedAvg Aggregation: UNIFORM WEIGHTS (Î±_i = 1/N)\n",
    "    alpha_uniform = [1.0 / N_CLIENTS_BASE] * N_CLIENTS_BASE\n",
    "    print(f\"  FedAvg Weights: {[f'{a:.3f}' for a in alpha_uniform]}\")\n",
    "    \n",
    "    # Apply uniform aggregation\n",
    "    sd = global_model_fedavg.state_dict()\n",
    "    for k in sd:\n",
    "        sd[k] = sd[k] + sum(a * u[k] for a, u in zip(alpha_uniform, updates_base))\n",
    "    global_model_fedavg.load_state_dict(sd)\n",
    "    \n",
    "    # Evaluate\n",
    "    acc_fedavg = evaluate_baseline(global_model_fedavg, test_loader_base, DEVICE_BASE)\n",
    "    history_fedavg['acc'].append(acc_fedavg)\n",
    "    history_fedavg['bias'].append(B_base_fedavg)\n",
    "    \n",
    "    wandb.log({'round': r+1, 'accuracy': acc_fedavg, 'bias': B_base_fedavg})\n",
    "    print(f\"  Accuracy: {acc_fedavg:.2f}%\")\n",
    "\n",
    "print(f\"\\nFedAvg Final Accuracy: {history_fedavg['acc'][-1]:.2f}%\")\n",
    "print(f\"FedAvg Final Bias: {history_fedavg['bias'][-1]:.4f}\")\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aff60d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# COMPARISON: Fed-Audit-GAN vs FedAvg\n",
    "# Additional Metrics: JFI, Variance, Max-Min Gap\n",
    "# ============================================================\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# ============================================================\n",
    "# FAIRNESS METRICS CALCULATION\n",
    "# ============================================================\n",
    "\n",
    "def calculate_jfi(weights):\n",
    "    \"\"\"\n",
    "    Jain's Fairness Index (JFI)\n",
    "    Formula: JFI = (Î£ Î±_i)Â² / (N Ã— Î£ Î±_iÂ²)\n",
    "    Range: 1/N (worst) to 1 (best/equal)\n",
    "    \"\"\"\n",
    "    weights = np.array(weights)\n",
    "    n = len(weights)\n",
    "    numerator = np.sum(weights) ** 2\n",
    "    denominator = n * np.sum(weights ** 2)\n",
    "    return numerator / denominator if denominator > 0 else 0\n",
    "\n",
    "def calculate_variance(weights):\n",
    "    \"\"\"\n",
    "    Variance of aggregation weights\n",
    "    Lower = more equal distribution\n",
    "    \"\"\"\n",
    "    return np.var(weights)\n",
    "\n",
    "def calculate_max_min_gap(weights):\n",
    "    \"\"\"\n",
    "    Max-Min Gap\n",
    "    Difference between highest and lowest weight\n",
    "    Lower = more equal distribution\n",
    "    \"\"\"\n",
    "    return np.max(weights) - np.min(weights)\n",
    "\n",
    "def calculate_coefficient_of_variation(weights):\n",
    "    \"\"\"\n",
    "    Coefficient of Variation (CV)\n",
    "    CV = std / mean\n",
    "    Lower = more equal distribution\n",
    "    \"\"\"\n",
    "    mean = np.mean(weights)\n",
    "    std = np.std(weights)\n",
    "    return std / mean if mean > 0 else 0\n",
    "\n",
    "# Calculate metrics for Fed-Audit-GAN (using last round's alpha weights)\n",
    "# We need to recalculate the final alpha weights\n",
    "S_final = []\n",
    "G_final = FairnessGenerator()\n",
    "D_final = Discriminator()\n",
    "G_final, D_final = train_gan(G_final, D_final, global_model, val_loader, epochs=5, device=DEVICE)\n",
    "G_final.eval()\n",
    "with torch.no_grad():\n",
    "    z_f = torch.randn(N_PROBES, G_final.latent_dim, device=DEVICE)\n",
    "    lbl_f = torch.randint(0, 10, (N_PROBES,), device=DEVICE)\n",
    "    x_f, xp_f = G_final(z_f, lbl_f)\n",
    "\n",
    "B_base_final = compute_bias(global_model, x_f, xp_f, DEVICE)\n",
    "# Simulate client updates for final metrics\n",
    "for c in range(N_CLIENTS):\n",
    "    loader = DataLoader(Subset(train_data, client_idx[c]), batch_size=32, shuffle=True)\n",
    "    local = copy.deepcopy(global_model)\n",
    "    before = copy.deepcopy(global_model.state_dict())\n",
    "    opt = optim.SGD(local.parameters(), lr=0.01)\n",
    "    local.train()\n",
    "    for _ in range(1):  # Quick update\n",
    "        for d, t in loader:\n",
    "            opt.zero_grad()\n",
    "            F.cross_entropy(local(d.to(DEVICE)), t.to(DEVICE)).backward()\n",
    "            opt.step()\n",
    "            break\n",
    "    upd = {k: local.state_dict()[k] - before[k] for k in before}\n",
    "    hyp = copy.deepcopy(global_model)\n",
    "    sd = hyp.state_dict()\n",
    "    for k in sd: sd[k] = sd[k] + upd[k]\n",
    "    hyp.load_state_dict(sd)\n",
    "    B_i = compute_bias(hyp, x_f, xp_f, DEVICE)\n",
    "    S_final.append(B_base_final - B_i)\n",
    "\n",
    "# Fed-Audit-GAN weights (fairness-aware)\n",
    "alpha_fedaudit = F.softmax(torch.tensor(S_final) * GAMMA, dim=0).numpy()\n",
    "\n",
    "# FedAvg weights (uniform)\n",
    "alpha_fedavg_uniform = np.array([1.0 / N_CLIENTS] * N_CLIENTS)\n",
    "\n",
    "# Calculate all metrics\n",
    "metrics_fedaudit = {\n",
    "    'JFI': calculate_jfi(alpha_fedaudit),\n",
    "    'Variance': calculate_variance(alpha_fedaudit),\n",
    "    'Max-Min Gap': calculate_max_min_gap(alpha_fedaudit),\n",
    "    'CV': calculate_coefficient_of_variation(alpha_fedaudit)\n",
    "}\n",
    "\n",
    "metrics_fedavg = {\n",
    "    'JFI': calculate_jfi(alpha_fedavg_uniform),\n",
    "    'Variance': calculate_variance(alpha_fedavg_uniform),\n",
    "    'Max-Min Gap': calculate_max_min_gap(alpha_fedavg_uniform),\n",
    "    'CV': calculate_coefficient_of_variation(alpha_fedavg_uniform)\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ðŸ“Š FAIRNESS METRICS COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\n{'Metric':<25} {'Fed-Audit-GAN':<20} {'FedAvg':<20} {'Interpretation'}\")\n",
    "print(\"-\" * 90)\n",
    "print(f\"{'JFI (Jain Index)':<25} {metrics_fedaudit['JFI']:.6f}{'':<10} {metrics_fedavg['JFI']:.6f}{'':<10} Higher = More Equal\")\n",
    "print(f\"{'Variance':<25} {metrics_fedaudit['Variance']:.6f}{'':<10} {metrics_fedavg['Variance']:.6f}{'':<10} Lower = More Equal\")\n",
    "print(f\"{'Max-Min Gap':<25} {metrics_fedaudit['Max-Min Gap']:.6f}{'':<10} {metrics_fedavg['Max-Min Gap']:.6f}{'':<10} Lower = More Equal\")\n",
    "print(f\"{'Coeff. of Variation':<25} {metrics_fedaudit['CV']:.6f}{'':<10} {metrics_fedavg['CV']:.6f}{'':<10} Lower = More Equal\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Aggregation Weights:\")\n",
    "print(f\"   Fed-Audit-GAN: {[f'{a:.4f}' for a in alpha_fedaudit]}\")\n",
    "print(f\"   FedAvg:        {[f'{a:.4f}' for a in alpha_fedavg_uniform]}\")\n",
    "\n",
    "# ============================================================\n",
    "# VISUALIZATION\n",
    "# ============================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "rounds = range(1, len(history['acc']) + 1)\n",
    "\n",
    "# Plot 1: Accuracy Comparison\n",
    "axes[0, 0].plot(rounds, history['acc'], 'b-o', label='Fed-Audit-GAN (Î³=2.0)', linewidth=2, markersize=8)\n",
    "axes[0, 0].plot(rounds, history_fedavg['acc'], 'r--s', label='FedAvg (Î³=0)', linewidth=2, markersize=8)\n",
    "axes[0, 0].set_xlabel('Round', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "axes[0, 0].set_title('Test Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].legend(fontsize=11)\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Bias Comparison\n",
    "axes[0, 1].plot(rounds, history['bias'], 'b-o', label='Fed-Audit-GAN (Î³=2.0)', linewidth=2, markersize=8)\n",
    "axes[0, 1].plot(rounds, history_fedavg['bias'], 'r--s', label='FedAvg (Î³=0)', linewidth=2, markersize=8)\n",
    "axes[0, 1].set_xlabel('Round', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Bias (B_base)', fontsize=12)\n",
    "axes[0, 1].set_title('Bias Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].legend(fontsize=11)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Aggregation Weights Bar Chart\n",
    "x_clients = np.arange(N_CLIENTS)\n",
    "width = 0.35\n",
    "bars1 = axes[0, 2].bar(x_clients - width/2, alpha_fedaudit, width, label='Fed-Audit-GAN', color='#3498db', edgecolor='black')\n",
    "bars2 = axes[0, 2].bar(x_clients + width/2, alpha_fedavg_uniform, width, label='FedAvg', color='#e74c3c', edgecolor='black')\n",
    "axes[0, 2].set_xlabel('Client ID', fontsize=12)\n",
    "axes[0, 2].set_ylabel('Aggregation Weight (Î±)', fontsize=12)\n",
    "axes[0, 2].set_title('Client Aggregation Weights', fontsize=14, fontweight='bold')\n",
    "axes[0, 2].set_xticks(x_clients)\n",
    "axes[0, 2].legend(fontsize=11)\n",
    "axes[0, 2].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 4: Final Accuracy Bar Chart\n",
    "methods = ['Fed-Audit-GAN', 'FedAvg']\n",
    "final_accs = [history['acc'][-1], history_fedavg['acc'][-1]]\n",
    "colors = ['#2ecc71', '#e74c3c']\n",
    "bars = axes[1, 0].bar(methods, final_accs, color=colors, edgecolor='black', linewidth=2)\n",
    "axes[1, 0].set_ylabel('Final Accuracy (%)', fontsize=12)\n",
    "axes[1, 0].set_title('Final Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_ylim([min(final_accs) - 5, max(final_accs) + 5])\n",
    "for bar, acc in zip(bars, final_accs):\n",
    "    axes[1, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
    "                    f'{acc:.2f}%', ha='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Plot 5: JFI Comparison\n",
    "jfi_values = [metrics_fedaudit['JFI'], metrics_fedavg['JFI']]\n",
    "bars = axes[1, 1].bar(methods, jfi_values, color=colors, edgecolor='black', linewidth=2)\n",
    "axes[1, 1].set_ylabel('JFI Score', fontsize=12)\n",
    "axes[1, 1].set_title('Jain\\'s Fairness Index\\n(1.0 = Perfect Equality)', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_ylim([0, 1.1])\n",
    "axes[1, 1].axhline(y=1.0, color='green', linestyle='--', label='Perfect JFI', linewidth=2)\n",
    "for bar, jfi in zip(bars, jfi_values):\n",
    "    axes[1, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
    "                    f'{jfi:.4f}', ha='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Plot 6: All Fairness Metrics Comparison\n",
    "metric_names = ['Variance\\n(Ã—100)', 'Max-Min\\nGap', 'CV']\n",
    "fedaudit_vals = [metrics_fedaudit['Variance']*100, metrics_fedaudit['Max-Min Gap'], metrics_fedaudit['CV']]\n",
    "fedavg_vals = [metrics_fedavg['Variance']*100, metrics_fedavg['Max-Min Gap'], metrics_fedavg['CV']]\n",
    "x_metrics = np.arange(len(metric_names))\n",
    "width = 0.35\n",
    "bars1 = axes[1, 2].bar(x_metrics - width/2, fedaudit_vals, width, label='Fed-Audit-GAN', color='#3498db', edgecolor='black')\n",
    "bars2 = axes[1, 2].bar(x_metrics + width/2, fedavg_vals, width, label='FedAvg', color='#e74c3c', edgecolor='black')\n",
    "axes[1, 2].set_ylabel('Value', fontsize=12)\n",
    "axes[1, 2].set_title('Fairness Metrics\\n(Lower = More Equal)', fontsize=14, fontweight='bold')\n",
    "axes[1, 2].set_xticks(x_metrics)\n",
    "axes[1, 2].set_xticklabels(metric_names)\n",
    "axes[1, 2].legend(fontsize=11)\n",
    "axes[1, 2].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('comparison_with_fairness_metrics.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# FINAL SUMMARY TABLE\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ðŸ“Š COMPLETE COMPARISON SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n{'METRIC':<30} {'FED-AUDIT-GAN':<20} {'FEDAVG':<20} {'WINNER'}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Accuracy\n",
    "acc_winner = \"Fed-Audit-GAN\" if history['acc'][-1] >= history_fedavg['acc'][-1] else \"FedAvg\"\n",
    "print(f\"{'Final Accuracy (%)':<30} {history['acc'][-1]:<20.2f} {history_fedavg['acc'][-1]:<20.2f} {acc_winner}\")\n",
    "\n",
    "# Bias\n",
    "bias_winner = \"Fed-Audit-GAN\" if history['bias'][-1] <= history_fedavg['bias'][-1] else \"FedAvg\"\n",
    "print(f\"{'Final Bias (Lower=Better)':<30} {history['bias'][-1]:<20.6f} {history_fedavg['bias'][-1]:<20.6f} {bias_winner}\")\n",
    "\n",
    "# JFI\n",
    "jfi_winner = \"FedAvg\" if metrics_fedavg['JFI'] >= metrics_fedaudit['JFI'] else \"Fed-Audit-GAN\"\n",
    "print(f\"{'JFI (Higher=More Equal)':<30} {metrics_fedaudit['JFI']:<20.6f} {metrics_fedavg['JFI']:<20.6f} {jfi_winner}\")\n",
    "\n",
    "# Variance\n",
    "var_winner = \"FedAvg\" if metrics_fedavg['Variance'] <= metrics_fedaudit['Variance'] else \"Fed-Audit-GAN\"\n",
    "print(f\"{'Variance (Lower=More Equal)':<30} {metrics_fedaudit['Variance']:<20.6f} {metrics_fedavg['Variance']:<20.6f} {var_winner}\")\n",
    "\n",
    "# Max-Min Gap\n",
    "gap_winner = \"FedAvg\" if metrics_fedavg['Max-Min Gap'] <= metrics_fedaudit['Max-Min Gap'] else \"Fed-Audit-GAN\"\n",
    "print(f\"{'Max-Min Gap (Lower=Better)':<30} {metrics_fedaudit['Max-Min Gap']:<20.6f} {metrics_fedavg['Max-Min Gap']:<20.6f} {gap_winner}\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\"\"\n",
    "ðŸ“ INTERPRETATION:\n",
    "   \n",
    "   1. JFI (Jain's Fairness Index):\n",
    "      Formula: JFI = (Î£Î±áµ¢)Â² / (N Ã— Î£Î±áµ¢Â²)\n",
    "      Range: 1/N (one client dominates) to 1.0 (perfectly equal)\n",
    "      FedAvg always has JFI = 1.0 (uniform weights)\n",
    "      Fed-Audit-GAN has JFI < 1.0 (intentionally favors fair clients)\n",
    "   \n",
    "   2. Variance:\n",
    "      Measures spread of weights around mean\n",
    "      FedAvg: Variance = 0 (all weights identical)\n",
    "      Fed-Audit-GAN: Variance > 0 (weights differ by fairness)\n",
    "   \n",
    "   3. Max-Min Gap:\n",
    "      Difference between highest and lowest weight\n",
    "      FedAvg: Gap = 0 (all clients equal)\n",
    "      Fed-Audit-GAN: Gap > 0 (fair clients get higher weight)\n",
    "   \n",
    "   âš¡ KEY INSIGHT:\n",
    "   Fed-Audit-GAN intentionally has \"worse\" JFI/Variance/Gap metrics\n",
    "   because it PURPOSEFULLY gives more weight to fairer clients!\n",
    "   This is the trade-off: weight equality vs fairness-awareness.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33364b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Plot Results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "ax1.plot(history['acc'], 'b-o')\n",
    "ax1.set_xlabel('Round'); ax1.set_ylabel('Accuracy (%)'); ax1.set_title('Test Accuracy'); ax1.grid(True)\n",
    "ax2.plot(history['bias'], 'r-s')\n",
    "ax2.set_xlabel('Round'); ax2.set_ylabel('Bias'); ax2.set_title('Baseline Bias'); ax2.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('results.png', dpi=150)\n",
    "plt.show()\n",
    "print(\"Check your WandB dashboard: https://wandb.ai\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
