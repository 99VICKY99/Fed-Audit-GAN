B.Tech. Major Project (CS499) – Weekly Progress Report 6
Student Details:
Name: Vicky Prasad and Shivansh
Roll No.: 22CSE1040 and 22CSE1034
Supervisor's Name: Dr. Pravati Swain
Reporting Period: [29th September 2025 – 03rd October 2025]
1. Progress Summary*
From our previous discussion on the 29th of September, we were asked to find more literature reviews in order to justify the research gap in FedHKT, and its resolution using GenAI. In the meantime, we were assigned another task, to read a few papers on “Fairness with federated learning”. Fairness is a new concept that has gained popularity as it deals with both the utilitarianist as well as the ethical aspects of Federated Learning. The server can be converged using clients with good resources, but this would mean that low resource clients (mobile phones, IOT devices etc) are abandoned. Hence, it becomes important to look into how to strike a balance between performance and fairness, and how different environments demand a new constraint with which the problem must be dealt with. 

Below are the papers that matched the above objective:

Fairness-Aware Client Selection for Federated Learning (Yuxin Shi, Zelei Liu, Zhuan Shi, Han Yu)

Abstract -- Federated learning (FL) has enabled multiple data owners (a.k.a. FL clients) to train machine learning models collaboratively without revealing private data. Since the FL server can only engage a limited number of clients in each training round, FL client selection has become an important research problem. Existing approaches generally focus on either enhancing FL model performance or enhancing the fair treatment of FL clients. The problem of balancing performance and fairness considerations when selecting FL clients remains open. To address this problem, we propose the Fairness-aware Federated Client Selection (FairFedCS) approach. Based on Lyapunov optimization, it dynamically adjusts FL clients’ selection probabilities by jointly considering their reputations, times of participation in FL tasks and contributions to the resulting model performance. By not using threshold-based reputation filtering, it provides FL clients with opportunities to redeem their reputations after a perceived poor performance, thereby further enhancing fair client treatment. Extensive experiments based on real-world multimedia datasets show that FairFedCS achieves 19.6% higher fairness and 0.73% higher test accuracy on average than the best-performing state-of-the-art approach.

FairFed: Enabling Group Fairness in Federated Learning (Yahya H. Ezzeldin, Shen Yan, Chaoyang He, Emilio Ferrara, Salman Avestimehr)

Abstract -- Training ML models which are fair across different demographic groups is of critical importance due to the increased integration of ML in crucial decision-making scenarios such as healthcare and recruitment. Federated learning has been viewed as a promising solution for collaboratively training machine learning models among multiple parties while maintaining their local data privacy. However, federated learning also poses new challenges in mitigating the potential bias against certain populations (e.g., demographic groups), as this typically requires centralized access to the sensitive information (e.g., race, gender) of each datapoint. Motivated by the importance and challenges of group fairness in federated learning, in this work, we propose FairFed, a novel algorithm for fairness-aware aggregation to enhance group fairness in federated learning. Our proposed approach is server-side and agnostic to the applied local debiasing thus allowing for flexible use of different local debiasing methods across clients. We evaluate FairFed empirically versus common baselines for fair ML and federated learning and demonstrate that it provides fairer models, particularly under highly heterogeneous data distributions across clients. We also demonstrate the benefits of FairFed in scenarios involving naturally distributed real-life data collected from different geographical locations or departments within an organization.

Fairness-Aware Federated Learning With Unreliable Links in Resource-Constrained Internet of Things (Zhidu Li , Member, IEEE, Yujie Zhou , Dapeng Wu , Senior Member, IEEE, Tong Tang , and Ruyan Wang)

Abstract -- In order to make full use of the network data and guarantee user privacy simultaneously, federated learning (FL) is proposed to enable distributed intelligence for local nodes without sharing data with each other. However, in practice, due to resource limitations, traditional FL suffers from node scheduling and parameter transmission failure, which not only affects the final performance but also further reduces the fairness of the participating nodes. This article addresses the challenge and proposes an FL method to enhance the performance of FL on the basis of guaranteeing the fairness of the local nodes in a resource-constrained Internet of Things (IoT) network. Specifically, an analytical model is first constructed to characterize the performance of FL with joint considerations of node fairness, unreliable parameter transmissions as well as resource limitations. Thereafter, a statistically reweighted aggregation (SRA) scheme is proposed for parameter aggregation and the corresponding model is proved to be unbiased to that based on ideal parameter transmissions. With the knowledge of time dependency of the global model, we further extend SRA and propose a reliable SRA (RSRA) scheme. Additionally, we prove RSRA is able to achieve higher stability performance than SRA in model training. Furthermore, the convergence bound of the proposed RSRA is derived analytically, based on which an adaptive local training scheme is proposed under a given resource budget. Finally, extensive experiments are carried out with a public data set to validate the effectiveness of the proposed scheme with comparisons of other baseline schemes.

FairEquityFL – A Fair and Equitable Client Selection in Federated Learning for Heterogeneous IoV Networks (Fahmida Islam , Adnan Mahmood, Noorain Mukhtiar, Kasun Eranda Wijethilake, and Quan Z. Sheng)

Abstract -- Federated Learning (FL) has been extensively employed for a number of applications in machine learning, i.e., primarily owing to its privacy preserving nature and efficiency in mitigating the communication overhead. Internet of Vehicles (IoV) is one of the promising applications, wherein FL can be utilized to train a model more efficiently. Since only a subset of the clients can participate in each FL training round, challenges arise pertinent to fairness in the client selection process. Over the years, a number of researchers from both academia and industry have proposed numerous FL frameworks. However, to the best of our knowledge, none of them have employed fairness for FL-based client selection in a dynamic and heterogeneous IoV environment. Accordingly, in this paper, we envisage a FairEquityFL framework to ensure an equitable opportunity for all the clients to participate in the FL training process. In particular, we have introduced a sampling equalizer module within the selector component for ensuring fairness in terms of fair collaboration opportunity for all the clients in the client selection process. The selector is additionally responsible for both monitoring and controlling the clients’ participation in each FL training round. Moreover, an outlier detection mechanism is enforced for identifying malicious clients based on the model performance in terms of considerable fluctuation in either accuracy or loss minimization. The selector flags suspicious clients and temporarily suspend such clients from participating in the FL training process. We further evaluate the performance of FairEquityFL on a publicly available dataset, FEMNIST. Our simulation results depict that FairEquityFL outperforms baseline models to a considerable extent

2. Tasks Completed This Week*
This week, we focused on understanding the concept of fairness in federated learning (FL) and how existing research approaches this challenge. Fairness in FL refers to ensuring that all participating clients, regardless of their data quality, network reliability, or resource capacity, have equitable chances to contribute to the global model without being consistently ignored or underrepresented. To study how this is achieved, we reviewed three recent papers and noted the different strategies they employ:
Reputation + Optimization (FairFedCS): clients are ranked using reputation (based on contribution) and virtual queues, balancing fairness and accuracy.
Rule-based Equity (FairEquityFL): fairness ensured by monitoring participation history (minimum/maximum gaps) and adding basic malicious client detection.
Weighted Aggregation under Unreliable Links (RSRA, IoT-FL): reweights updates by link reliability and uses a fairness parameter (q) to reduce bias toward strong clients.
Group Fairness (FairFed): extends fairness to groups of clients (e.g., demographic groups), ensuring that global model performance is equitable across groups rather than just across individuals.

3. Plan for the Upcoming Week*
In the coming week, our focus will be on consolidating the insights gained from the reviewed papers and identifying a concrete direction for our own contribution. Specifically, we plan to outline a potential hybrid framework that integrates fairness, reliability, and security in federated learning, drawing from the strengths of FairFedCS, FairEquityFL, and RSRA. Alongside this, we will begin drafting the problem statement and research objectives, highlighting the gap of limited real-world validation.
4. Additional Notes*

N/A

Student’s Signature: ___________________
Supervisor’s Remarks: The research progress report is satisfactory / not-satisfactory (if not satisfactory, specific reasons must be furnished separately)


Supervisor’s Signature: ___________________